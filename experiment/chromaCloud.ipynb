{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ycfs6s2CZt2gAfIVpryebTZsy-7bQBwB?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "- No coding experience required\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sVkDeT8NS88w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chroma Cloud : From Basics to a Mini RAG App\n",
        "\n",
        "- **Goal**: Learn how to add, retrieve, and query text with Chroma cloud\n",
        "- **What you'll do**:\n",
        "  - Install and set up dependencies\n",
        "  - Create a client and collection\n",
        "  - Add and query documents (including `get_or_create` and `upsert`)\n",
        "  - Build a simple RAG pipeline using OpenAI models\n",
        "\n",
        "Tip: Run each cell in sequence. This notebook is designed for Google Colab."
      ],
      "metadata": {
        "id": "wusaQLIsdP6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install All required libraries and setup you OPENAI API KEY and set up [chromaDB](https://www.trychroma.com/) cloud database and token id"
      ],
      "metadata": {
        "id": "LCBSwR8nRQ2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb openai --quiet"
      ],
      "metadata": {
        "id": "LVOfiEGcBdPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "chroma_token = userdata.get('CHROMA_TOKEN')"
      ],
      "metadata": {
        "id": "WcMxFAMmZuUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chroma Basics\n",
        "\n",
        "We mirror the steps from the reference:\n",
        "1. Create a client\n",
        "2. Create a collection\n",
        "3. Add documents with ids\n",
        "4. Query similar documents\n",
        "\n",
        "Notes:\n",
        "- Chroma can embed for you with defaults.\n",
        "- `ids` must be unique strings.\n"
      ],
      "metadata": {
        "id": "DfR9ZGwqde2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3r01I2sBZAA"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "# 1. Create a Chroma Client\n",
        "client = chromadb.HttpClient(\n",
        "  ssl=True,\n",
        "  host='api.trychroma.com',\n",
        "  tenant='6b53ed41-c379-47fa-b956-cc402f6fced8',\n",
        "  database='cloud_quickstart',\n",
        "  headers={\n",
        "    'x-chroma-token': f'{chroma_token}'\n",
        "  }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create a collection\n",
        "collection = client.create_collection(name=\"my_collection\")\n",
        "\n",
        "# 3. Add documents with unique IDs\n",
        "collection.add(\n",
        "    ids=[\"id1\", \"id2\"],\n",
        "    documents=[\n",
        "        \"This is a document about pineapple\",\n",
        "        \"This is a document about oranges\",\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHdzh6Z4c55p",
        "outputId": "ea06fa96-f2a0-4621-85fb-8ae23d1fad35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:00<00:00, 104MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Query the collection\n",
        "results = collection.query(\n",
        "    query_texts=[\"This is a query document\"],\n",
        "    n_results=2,\n",
        ")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJAjfvfKdGGl",
        "outputId": "2a4e527d-4c61-4326-a187-1379e4144c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['id1', 'id2']],\n",
              " 'distances': [[1.2771862, 1.2883999]],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [[None, None]],\n",
              " 'documents': [['This is a document about pineapple',\n",
              "   'This is a document about oranges']],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents', 'distances']}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using get_or_create and upsert\n",
        "\n",
        "- **Why**: Avoid recreating the collection or duplicating docs on reruns.\n",
        "- **get_or_create**: Returns existing collection or creates one if missing.\n",
        "- **upsert**: Insert or update documents by ID.\n"
      ],
      "metadata": {
        "id": "FFtbr81Ndjbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection = client.get_or_create_collection(name=\"customer-support-messages\")\n"
      ],
      "metadata": {
        "id": "zyPYOslMZTIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    query_texts=[\"I accidentally deleted several project boards yesterday and thought I could restore them\"], # Chroma will embed this for you\n",
        "    n_results=2 # how many results to return\n",
        ")\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B1z-w01ZnIX",
        "outputId": "03ba43ed-70ad-4e44-e526-0e5dbf7d1ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['e8789e2b-3dbe-4c9f-a4de-2396ce4d1bb3', 'cd1b60e5-702b-4e71-9496-db261ce624b6']], 'distances': [[0.4520844, 0.59681433]], 'embeddings': None, 'metadatas': [[{'timestamp': '2025-06-06T19:44:15.941Z', 'unix_timestamp': 1749239055, 'from_email': 'troy.pfeffer18@example.com'}, {'from_email': 'pearlie.langworth64@example.com', 'unix_timestamp': 1749240323, 'timestamp': '2025-06-06T20:05:23.791Z'}]], 'documents': [['I accidentally deleted several project boards yesterday and thought I could restore them, but the backup option only shows data from two weeks ago. Is there a way to access a more recent snapshot or undo the deletion without losing the work my team added this week?', 'Yesterday I accidentally overwrote my main project board while importing a template, and all the tasks and comments vanished. How can I roll back to a previous version or restore a backup if I never manually triggered one?']], 'uris': None, 'data': None, 'included': ['metadatas', 'documents', 'distances']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini RAG App\n",
        "\n",
        "We will:\n",
        "- Embed a small corpus into Chroma\n",
        "- Retrieve top-k docs for a user query\n",
        "- Generate an answer with OpenAI using retrieved context\n",
        "\n",
        "Architecture:\n",
        "- `embed(texts) -> vectors`\n",
        "- `store(vectors, metadata) -> collection`\n",
        "- `retrieve(query) -> top_k docs`\n",
        "- `answer(query, context) -> response`\n"
      ],
      "metadata": {
        "id": "FOQSO67RdqHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List\n",
        "\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "rag_client = chromadb.HttpClient(\n",
        "  ssl=True,\n",
        "  host='api.trychroma.com',\n",
        "  tenant='6b53ed41-c379-47fa-b956-cc402f6fced8',\n",
        "  database='cloud_quickstart',\n",
        "  headers={\n",
        "    'x-chroma-token': f'{chroma_token}'\n",
        "  }\n",
        ")\n",
        "\n",
        "# Use OpenAI embeddings via Chroma's helper\n",
        "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=openai_api_key,\n",
        "    model_name=\"text-embedding-3-small\"\n",
        ")\n",
        "\n",
        "rag_collection = rag_client.get_or_create_collection(\n",
        "    name=\"rag_collection\",\n",
        "    embedding_function=openai_ef,\n",
        ")\n",
        "\n",
        "print(\"RAG collection ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1od_ZPDM9qf",
        "outputId": "70e080a2-376d-46b5-946c-b94ca10e7e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG collection ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load a small corpus\n",
        "\n",
        "- Mix short documents with simple metadata\n",
        "- Use stable, unique string IDs\n",
        "- Upsert so you can re-run safely\n"
      ],
      "metadata": {
        "id": "MeDAnA39M_qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"Hawaii is known for pineapples and beautiful beaches.\",\n",
        "    \"Florida is famous for oranges and sunny weather.\",\n",
        "    \"Pineapple can be grown in tropical climates.\",\n",
        "    \"Oranges are rich in vitamin C and grow well in warm regions.\",\n",
        "]\n",
        "\n",
        "metas = [\n",
        "    {\"source\": \"wiki\", \"topic\": \"hawaii\"},\n",
        "    {\"source\": \"wiki\", \"topic\": \"florida\"},\n",
        "    {\"source\": \"notes\", \"topic\": \"pineapple\"},\n",
        "    {\"source\": \"notes\", \"topic\": \"oranges\"},\n",
        "]\n",
        "\n",
        "ids = [f\"doc-{i}\" for i in range(len(docs))]\n",
        "\n",
        "rag_collection.upsert(documents=docs, metadatas=metas, ids=ids)\n",
        "print(\"Inserted/updated\", len(docs), \"docs into rag_collection.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKUXVFWPNAdo",
        "outputId": "9a8318ad-d249-44aa-f28a-ed351acfb10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted/updated 4 docs into rag_collection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve and answer\n",
        "\n",
        "- Retrieve top-k docs for a query\n",
        "- Call OpenAI to produce an answer grounded in the retrieved context\n",
        "- Keep prompts concise and include citations\n"
      ],
      "metadata": {
        "id": "XogVOMUmNEZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "def retrieve(query: str, k: int = 3) -> Dict:\n",
        "    return rag_collection.query(query_texts=[query], n_results=k)\n",
        "\n",
        "\n",
        "def build_context(results: Dict) -> str:\n",
        "    docs = results.get(\"documents\", [[]])[0]\n",
        "    metadatas = results.get(\"metadatas\", [[]])[0]\n",
        "    parts = []\n",
        "    for i, (d, m) in enumerate(zip(docs, metadatas), start=1):\n",
        "        parts.append(f\"[Doc {i}] {d}\\n(Source: {m})\")\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "\n",
        "def answer_query(query: str, k: int = 3, model: str = \"gpt-4o-mini\") -> Dict[str, str]:\n",
        "    results = retrieve(query, k=k)\n",
        "    context = build_context(results)\n",
        "    prompt = (\n",
        "        \"You are a helpful assistant. Use the provided context to answer the question.\\n\"\n",
        "        \"If the answer isn't in the context, say you don't know.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "    chat = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Answer strictly based on the given context.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "    )\n",
        "\n",
        "    answer = chat.choices[0].message.content\n",
        "    return {\"answer\": answer, \"context\": context}\n"
      ],
      "metadata": {
        "id": "ukiTMeUxNFOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it\n",
        "qa = answer_query(\"Where are oranges commonly grown?\", k=2)\n",
        "print(\"Answer:\\n\", qa[\"answer\"])\n",
        "print(\"\\nContext used:\\n\", qa[\"context\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjhx7GvxNIRE",
        "outputId": "64d23a9d-4138-45a9-ed59-f832bf4e8d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " Oranges are commonly grown in warm regions.\n",
            "\n",
            "Context used:\n",
            " [Doc 1] Oranges are rich in vitamin C and grow well in warm regions.\n",
            "(Source: {'topic': 'oranges', 'source': 'notes'})\n",
            "\n",
            "[Doc 2] Florida is famous for oranges and sunny weather.\n",
            "(Source: {'source': 'wiki', 'topic': 'florida'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tips and Notes\n",
        "\n",
        "- **Unique IDs**: Keep `ids` stable to avoid duplicates and enable updates via `upsert`.\n",
        "- **Embeddings model**: `text-embedding-3-small` is cheap and strong; upgrade to `text-embedding-3-large` for best accuracy.\n",
        "- **Quality**: Better chunking and metadata improve retrieval.\n",
        "- **Safety**: Never hardcode API keys in notebooks you share.\n",
        "- **Reproducibility**: Use `get_or_create_collection` and `upsert` in examples for reruns.\n",
        "\n",
        "Next steps:\n",
        "- Add chunking, re-ranking (e.g., rerankers), and streaming answers.\n",
        "- Swap the chat model or prompt for your domain.\n"
      ],
      "metadata": {
        "id": "WmPGkrOxNJ8w"
      }
    }
  ]
}