{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1DiGmuC_-XfrYhBo7Pm8NshAdddMzAc0l?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "- Join Innovation Community\n",
        "\n",
        "Learn by building. Get expert mentorship and work on real AI projects.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P22s1RD-G1CH"
      },
      "source": [
        "## Exploring Instructor\n",
        "\n",
        "Python library for getting structured outputs from LLMs\n",
        "\n",
        "Github: https://github.com/jxnl/instructor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoXOi8IHV0Zl"
      },
      "source": [
        "Observations:\n",
        "- works well with OpenAI and Anthropic models\n",
        "- facing error when working with Together models\n",
        "\n",
        "Experiments:\n",
        "- Test for MCQ creation\n",
        "- Test for Resume Parsing\n",
        "- Integration with Educhain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SYdPfm1GrDm",
        "outputId": "2ec2bf21-dbbb-42a7-bd56-5a15731aae16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.7/862.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU instructor openai anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "awYXR3TrIAed",
        "outputId": "844af671-7881-4f14-b74c-acc145109f70"
      },
      "outputs": [
        {
          "ename": "SecretNotFoundError",
          "evalue": "Secret ANTHROPIC_API_KEY does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-153b5539208f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ANTHROPIC_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ANTHROPIC_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DEEPINFRA_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEEPINFRA_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret ANTHROPIC_API_KEY does not exist."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('ANTHROPIC_API_KEY')\n",
        "os.environ[\"DEEPINFRA_API_KEY\"] = userdata.get('DEEPINFRA_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGwYcIvfHF0p",
        "outputId": "8ada3d7f-d84f-48ec-e142-61357560017e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build Fast with AI\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "import instructor\n",
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "\n",
        "class UserInfo(BaseModel):\n",
        "  name: str\n",
        "  age: int\n",
        "\n",
        "client = instructor.from_openai(OpenAI())\n",
        "\n",
        "\n",
        "user_info = client.chat.completions.create(\n",
        "    model = \"gpt-4o\",\n",
        "    response_model = UserInfo,\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Build Fast with AI is 6 months old.\"}]\n",
        ")\n",
        "\n",
        "print(user_info.name)\n",
        "print(user_info.age)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-GosYiJVzil",
        "outputId": "051fb13a-7038-4aaa-bf32-45ed0f2ee859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "questions=[MCQ(question='Which of the following is not a bone in the human body?', options=[Option(text='Femur', correct='false'), Option(text='Mandible', correct='false'), Option(text='Sternum', correct='false'), Option(text='Fibula', correct='true')], explanation=None, blooms_level=None, difficulty_level=None, difficulty_rating=3, metadata={}), MCQ(question='Which organ is responsible for filtering blood in the human body?', options=[Option(text='Liver', correct='false'), Option(text='Kidneys', correct='true'), Option(text='Pancreas', correct='false'), Option(text='Lungs', correct='false')], explanation=None, blooms_level=None, difficulty_level=None, difficulty_rating=2, metadata={})]\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Dict, Any, Optional\n",
        "from pydantic import BaseModel, Field, validator\n",
        "\n",
        "## Models for tracking MCQs\n",
        "class Option(BaseModel):\n",
        "    text: str = Field(description=\"The text of the option.\")\n",
        "    correct: str = Field(description=\"Whether the option is correct or not. Either 'true' or 'false'\")\n",
        "\n",
        "\n",
        "class MCQ(BaseModel):\n",
        "    question: str = Field(description=\"The quiz question\")\n",
        "    options: List[Option] = Field(description=\"The possible answers to the question. The list should contain 4 options.\")\n",
        "    explanation: str = Field(default=None, description=\"Explanation of the question\")\n",
        "    blooms_level: str = Field(default=None, description=\"The Bloom's taxonomy level of the question\")\n",
        "    difficulty_level: str = Field(default=None, description=\"The difficulty level of the question. Can be 'easy', 'medium' or 'hard' \")\n",
        "    difficulty_rating: int = Field(ge=1, le=5, description=\"The difficulty rating of the question (1-5)\")\n",
        "    metadata: Dict[str, Any] = Field(default={}, description=\"Additional metadata for the question.\")\n",
        "\n",
        "class MCQList(BaseModel):\n",
        "    questions: List[MCQ]\n",
        "\n",
        "client = instructor.from_openai(OpenAI())\n",
        "\n",
        "questions = client.chat.completions.create(\n",
        "    model = \"gpt-4o\",\n",
        "    response_model = MCQList,\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Create 2 MCQs on Human Anatomy\"}]\n",
        ")\n",
        "\n",
        "print(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj7Nh15bWnNu",
        "outputId": "f0772e4a-2df8-46d1-8cb2-13ad77174cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question\": \"Which of the following is not a bone in the human body?\",\n",
            "      \"options\": [\n",
            "        {\n",
            "          \"text\": \"Femur\",\n",
            "          \"correct\": \"false\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Mandible\",\n",
            "          \"correct\": \"false\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Sternum\",\n",
            "          \"correct\": \"false\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Fibula\",\n",
            "          \"correct\": \"true\"\n",
            "        }\n",
            "      ],\n",
            "      \"explanation\": null,\n",
            "      \"blooms_level\": null,\n",
            "      \"difficulty_level\": null,\n",
            "      \"difficulty_rating\": 3,\n",
            "      \"metadata\": {}\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"Which organ is responsible for filtering blood in the human body?\",\n",
            "      \"options\": [\n",
            "        {\n",
            "          \"text\": \"Liver\",\n",
            "          \"correct\": \"false\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Kidneys\",\n",
            "          \"correct\": \"true\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Pancreas\",\n",
            "          \"correct\": \"false\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Lungs\",\n",
            "          \"correct\": \"false\"\n",
            "        }\n",
            "      ],\n",
            "      \"explanation\": null,\n",
            "      \"blooms_level\": null,\n",
            "      \"difficulty_level\": null,\n",
            "      \"difficulty_rating\": 2,\n",
            "      \"metadata\": {}\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(questions.model_dump_json(indent= 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmd-WgF-aEMy",
        "outputId": "7d1b9bab-a3d5-4f5f-ace3-4807235e6b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question\": \"What is the first law of thermodynamics?\",\n",
            "      \"options\": [\n",
            "        {\n",
            "          \"text\": \"Energy can be created or destroyed.\",\n",
            "          \"correct\": \"false\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Energy can be transformed from one form to another, but the total energy of an isolated system is constant.\",\n",
            "          \"correct\": \"true\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Energy can be converted into work, and work can be converted into energy.\",\n",
            "          \"correct\": \"true\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Energy can be neither created nor destroyed, but it can be transformed from one form to another.\",\n",
            "          \"correct\": \"true\"\n",
            "        }\n",
            "      ],\n",
            "      \"explanation\": \"The first law of thermodynamics states that energy can be transformed from one form to another, but the total energy of an isolated system is constant. It also states that energy can be converted into work, and work can be converted into energy.\",\n",
            "      \"blooms_level\": \"Remember\",\n",
            "      \"difficulty_level\": \"easy\",\n",
            "      \"difficulty_rating\": 2,\n",
            "      \"metadata\": {}\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"What is the second law of thermodynamics?\",\n",
            "      \"options\": [\n",
            "        {\n",
            "          \"text\": \"Heat can spontaneously flow from a colder object to a hotter object.\",\n",
            "          \"correct\": \"false\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"The entropy of an isolated system not in equilibrium will tend to increase over time, approaching a maximum value at equilibrium.\",\n",
            "          \"correct\": \"true\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"The entropy of the universe is always increasing.\",\n",
            "          \"correct\": \"true\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"All of the above.\",\n",
            "          \"correct\": \"true\"\n",
            "        }\n",
            "      ],\n",
            "      \"explanation\": \"The second law of thermodynamics states that the entropy of an isolated system not in equilibrium will tend to increase over time, approaching a maximum value at equilibrium. It also states that the entropy of the universe is always increasing.\",\n",
            "      \"blooms_level\": \"Understand\",\n",
            "      \"difficulty_level\": \"medium\",\n",
            "      \"difficulty_rating\": 3,\n",
            "      \"metadata\": {}\n",
            "    },\n",
            "    {\n",
            "      \"question\": \"Which of the following is a statement of the second law of thermodynamics?\",\n",
            "      \"options\": [\n",
            "        {\n",
            "          \"text\": \"Energy can be transformed from one form to another, but it cannot be created or destroyed.\",\n",
            "          \"correct\": \"false\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Heat can only flow spontaneously from a hotter object to a colder object.\",\n",
            "          \"correct\": \"true\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"The entropy of an isolated system not in equilibrium will tend to increase over time.\",\n",
            "          \"correct\": \"true\"\n",
            "        },\n",
            "        {\n",
            "          \"text\": \"Both B and C are correct.\",\n",
            "          \"correct\": \"true\"\n",
            "        }\n",
            "      ],\n",
            "      \"explanation\": \"The second law of thermodynamics states that heat can only flow spontaneously from a hotter object to a colder object, and that the entropy of an isolated system not in equilibrium will tend to increase over time.\",\n",
            "      \"blooms_level\": \"Understand\",\n",
            "      \"difficulty_level\": \"medium\",\n",
            "      \"difficulty_rating\": 4,\n",
            "      \"metadata\": {}\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# testing with Anthropic models\n",
        "\n",
        "from anthropic import Anthropic\n",
        "\n",
        "anthropic_client = instructor.from_anthropic(Anthropic())\n",
        "\n",
        "# note that client.chat.completions.create will also work\n",
        "resp = anthropic_client.messages.create(\n",
        "    model=\"claude-3-7-sonnet-latest\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Create 3 MCQs on Thermodynamics\",\n",
        "        }\n",
        "    ],\n",
        "    response_model=MCQList,\n",
        ")\n",
        "\n",
        "print(resp.model_dump_json(indent = 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "collapsed": true,
        "id": "dSmTgB17WnKt",
        "outputId": "4f49202b-8fa6-4a6b-bc73-30ba5ac57561"
      },
      "outputs": [],
      "source": [
        "# testing with Anyscale model\n",
        "\n",
        "import os\n",
        "import openai\n",
        "from pydantic import BaseModel\n",
        "import instructor\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://api.endpoints.anyscale.com/v1\",\n",
        "    api_key= userdata.get('ANYSCALE_API_KEY'),\n",
        ")\n",
        "\n",
        "# Patch the client to use Instructor's tools mode for structured outputs\n",
        "client = instructor.from_openai(client)\n",
        "\n",
        "# Define a Pydantic model for the structured response\n",
        "class UserExtract(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "\n",
        "# Use the patched client to create a chat completion with a structured response\n",
        "user: UserExtract = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
        "    response_model=UserExtract,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "# Output the structured data as JSON\n",
        "print(user.model_dump_json(indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "collapsed": true,
        "id": "ONDpS91XS__z",
        "outputId": "31c96169-ed27-4c70-9798-f55593f331e6"
      },
      "outputs": [],
      "source": [
        "# testing with Together model\n",
        "\n",
        "import os\n",
        "import openai\n",
        "from pydantic import BaseModel\n",
        "import instructor\n",
        "\n",
        "# Set up the Together AI client with your API key\n",
        "client = openai.OpenAI(\n",
        "    base_url=\"https://api.together.xyz/v1\",\n",
        "    api_key= userdata.get('TOGETHER_API_KEY'),\n",
        ")\n",
        "\n",
        "# Patch the client to use Instructor's tools mode for structured outputs\n",
        "client = instructor.from_openai(client, mode=instructor.Mode.TOOLS)\n",
        "\n",
        "# Define a Pydantic model for the structured response\n",
        "class UserExtract(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "\n",
        "# Use the patched client to create a chat completion with a structured response\n",
        "user: UserExtract = client.chat.completions.create(\n",
        "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    response_model=UserExtract,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Assertions to ensure the response matches the expected structure\n",
        "assert isinstance(user, UserExtract), \"Should be instance of UserExtract\"\n",
        "assert user.name.lower() == \"jason\"\n",
        "assert user.age == 25\n",
        "\n",
        "# Output the structured data as JSON\n",
        "print(user.model_dump_json(indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
