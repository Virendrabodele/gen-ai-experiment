{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1E86wcHZ9HIErTrKwrZcAUAKjb4m77smp?usp=sharing)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "metadata": {
        "id": "d5-41KSiQB7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Prompt Engineering with Promptify\n",
        "\n",
        "Solve NLP problems effortlessly with **Promptify**, an intuitive tool to generate prompts for popular generative models like **GPT**, **PaLM**, and more. Perform various NLP tasks (such as **NER** and **classification**) in just **2 lines of code** with **no training data required**.\n",
        "\n",
        "## üî• Features\n",
        "\n",
        "- üß© **Easy Prompt Generation** ‚Äì Easily generate prompts for different NLP tasks like NER and classification.\n",
        "- üí° **Few-Shot Learning** ‚Äì Add one-shot, two-shot, or few-shot examples to the prompt for better performance.\n",
        "- üö´ **Out-of-Bounds Prediction Handling** ‚Äì Handle out-of-bounds predictions from LLMs (GPT, T5, etc.) with ease.\n",
        "- üêç **Structured Output** ‚Äì Output is always provided as a Python object (e.g., list, dictionary), making it easy to parse and filter for business or application needs.\n",
        "- üìë **Custom Examples** ‚Äì Easily add custom examples and samples to enhance prompt quality."
      ],
      "metadata": {
        "id": "1zJVwEUJQB12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üì¶ **Dependency Installation**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vRYCKeUUQBv1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm7uwRTvlT6_"
      },
      "outputs": [],
      "source": [
        "!pip install promptify"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîß Setup API Key**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TfSj_WpFVJfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "api_key=userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "XCeVFjfol93Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üß† NER with Promptify for Medical Text üè•**\n"
      ],
      "metadata": {
        "id": "kpwx6CV6QCk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from promptify import Prompter,OpenAI, Pipeline\n",
        "\n",
        "sentence     =  \"\"\"The patient is a 93-year-old female with a medical\n",
        "                history of chronic right hip pain, osteoporosis,\n",
        "                hypertension, depression, and chronic atrial\n",
        "                fibrillation admitted for evaluation and management\n",
        "                of severe nausea and vomiting and urinary tract\n",
        "                infection\"\"\"\n",
        "\n",
        "model        = OpenAI(api_key)\n",
        "prompter     = Prompter('ner.jinja')\n",
        "pipe         = Pipeline(prompter , model)\n",
        "\n",
        "\n",
        "result = pipe.fit(sentence, domain=\"medical\", labels=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc3Equizlg-u",
        "outputId": "7a193584-481d-40d6-d986-b3e82f0e7ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.54s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ee_IzwOmjUP",
        "outputId": "e88939ee-66a9-4282-d7d3-57b5cc3dfd95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': '[\\n    {\"T\": \"Age\", \"E\": \"93-year-old\"},\\n    {\"T\": \"Gender\", \"E\": \"female\"},\\n    {\"T\": \"Medical Condition\", \"E\": \"chronic right hip pain\"},\\n    {\"T\": \"Medical Condition\", \"E\": \"osteoporosis\"},\\n    {\"T\": \"Medical Condition\", \"E\": \"hypertension\"},\\n    {\"T\": \"Medical Condition\", \"E\": \"depression\"},\\n    {\"T\": \"Medical Condition\", \"E\": \"chronic atrial fibrillation\"},\\n    {\"T\": \"Reason for Admission\", \"E\": \"evaluation and management of severe nausea and vomiting and urinary tract infection\"},\\n    {\"branch\": \"Medical\", \"group\": \"Patient Information\"}\\n]', 'usage': {'prompt_tokens': 203, 'completion_tokens': 155, 'total_tokens': 358, 'prompt_tokens_details': <OpenAIObject at 0x7863388013d0> JSON: {\n",
            "  \"audio_tokens\": 0,\n",
            "  \"cached_tokens\": 0\n",
            "}, 'completion_tokens_details': <OpenAIObject at 0x786338801430> JSON: {\n",
            "  \"accepted_prediction_tokens\": 0,\n",
            "  \"audio_tokens\": 0,\n",
            "  \"reasoning_tokens\": 0,\n",
            "  \"rejected_prediction_tokens\": 0\n",
            "}}, 'parsed': {'status': 'completed', 'object_type': <class 'list'>, 'data': {'completion': [{'T': 'Age', 'E': '93-year-old'}, {'T': 'Gender', 'E': 'female'}, {'T': 'Medical Condition', 'E': 'chronic right hip pain'}, {'T': 'Medical Condition', 'E': 'osteoporosis'}, {'T': 'Medical Condition', 'E': 'hypertension'}, {'T': 'Medical Condition', 'E': 'depression'}, {'T': 'Medical Condition', 'E': 'chronic atrial fibrillation'}, {'T': 'Reason for Admission', 'E': 'evaluation and management of severe nausea and vomiting and urinary tract infection'}, {'branch': 'Medical', 'group': 'Patient Information'}], 'suggestions': []}}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from promptify import Prompter, OpenAI, Pipeline\n",
        "from pprint import pprint\n",
        "import os"
      ],
      "metadata": {
        "id": "Qdr-VdtoPenS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "VDCigWPuPf0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìú Template for Binary Classification Prompt**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XS-g3KatVTMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\"\n",
        "{%- if description is not none -%}\n",
        "{{ description }}\n",
        "{% endif -%}\n",
        "\n",
        "You are a highly intelligent and accurate Binary Classification system. You take Passage as input and classify that as either {{ label_0 }} or {{ label_1 }} Category. Your output format is only {{ output_format|default(\"[{'C':Category}]\") }} form, no other form.\n",
        "\n",
        "{% if examples is defined and examples|length > 0 -%}\n",
        "Examples:\n",
        "{% for sentence, label in examples %}\n",
        "Input: {{ sentence }}\n",
        "Output: [{'C': '{{ label }}' }]\n",
        "{% endfor %}\n",
        "{% endif -%}\n",
        "\n",
        "Input: {{ text_input }}\n",
        "Output:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hB-wjO5DPf6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìä Define Input Data for Binary Classification**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PQTBjpkZVV16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['positive', 'negative']\n",
        "data = [\n",
        "    {'text': 'This is great', 'label': 'positive'},\n",
        "    {'text': 'This is awful', 'label': 'negative'}\n",
        "]\n",
        "sent = \"The patient is a 93-year-old female with a medical history of chronic right hip pain, osteoporosis, hypertension, depression, and chronic atrial fibrillation admitted for evaluation and management of severe nausea and vomiting and urinary tract infection\"  # Input text"
      ],
      "metadata": {
        "id": "ak_i1OCSPf-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚öôÔ∏è Initialize Prompter, Model, and Pipeline**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mnvR1l_pVdIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = OpenAI(api_key=api_key, model=model_name)\n",
        "prompter = Prompter(template=template_string, from_string=True)\n",
        "pipe = Pipeline(prompter, model)"
      ],
      "metadata": {
        "id": "KQy4dXazP2Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üöÄ Run the Pipeline for Classification**\n"
      ],
      "metadata": {
        "id": "qk32Xr2fVkNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe.fit(sent, label_0=labels[0], label_1=labels[1], examples=data)\n",
        "\n",
        "print(result[0])\n"
      ],
      "metadata": {
        "id": "zmwuQlGoP4xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üõ†Ô∏è Template, Model, and Pipeline Setup**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tGBG2MOqQEVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"Translate to Spanish: {{text_input}}\"\n",
        "model = OpenAI(api_key, model=\"gpt-3.5-turbo\")\n",
        "prompter = Prompter(template, from_string=True)\n",
        "\n",
        "\n",
        "pipe = Pipeline(prompter, model, structured_output = False)"
      ],
      "metadata": {
        "id": "bi_A9kzvQY5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîÑ Process and Print Result**\n"
      ],
      "metadata": {
        "id": "VkG8rHX1Vvzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world!\"\n",
        "result = pipe.fit(text)\n",
        "\n",
        "if result:\n",
        "    print(result[0])\n",
        "else:\n",
        "    print(\"No result.\")"
      ],
      "metadata": {
        "id": "5FlQHbdnQZji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìù Template Definition for Sentiment Analysis**\n"
      ],
      "metadata": {
        "id": "Em6IC9HjQppO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Classify the sentiment of the following text as positive or negative.\n",
        "Text: {{text_input}}\n",
        "Sentiment:\"\"\""
      ],
      "metadata": {
        "id": "G3Y12L4HQcUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîß Initializing Promptify Objects**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SSjLhby0WFh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompter = Prompter(template, from_string=True)\n",
        "pipe = Pipeline(prompter, model, structured_output=False)"
      ],
      "metadata": {
        "id": "jWNzhc5TSsvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This movie was amazing!  I loved it.\"\n",
        "result = pipe.fit(text)\n",
        "\n",
        "if result:\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Sentiment: {result[0]}\")\n",
        "else:\n",
        "    print(\"No result.\")"
      ],
      "metadata": {
        "id": "X5fh7bCgSuOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " print(f\"Sentiment: {result[0]['choices'][0]['message']['content']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-wwCBU9Svek",
        "outputId": "5cd79335-46fc-4ae2-ef38-180ec5c2198d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìù Template Definition for Topic Extraction**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9A92kNTeWNl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Extract the main topic from the following text:\n",
        "Text: {{text_input}}\n",
        "Topic:\"\"\""
      ],
      "metadata": {
        "id": "7hlJWdvoTSvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîß Initializing Promptify Components**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AYyaWFyqWRXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompter = Prompter(template, from_string=True)\n",
        "pipe = Pipeline(prompter, model, structured_output=False)"
      ],
      "metadata": {
        "id": "l6LTMNtbTTET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The quick brown fox jumps over the lazy dog.  It's a common English pangram.\"\n",
        "result = pipe.fit(text)\n",
        "\n",
        "if result:\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Topic: {result[0]}\")\n",
        "else:\n",
        "    print(\"No result.\")"
      ],
      "metadata": {
        "id": "bBQHPV7HTUbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Summary: {result[0]['choices'][0]['message']['content']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr76TOouTVqi",
        "outputId": "b1bfe1be-c5c3-4822-f1b6-68d13feb0c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: The main topic of the text is a common English pangram.\n"
          ]
        }
      ]
    }
  ]
}