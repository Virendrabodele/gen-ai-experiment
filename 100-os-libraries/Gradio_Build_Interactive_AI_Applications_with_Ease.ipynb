{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1gMjgnNFWBhQlLwPJBKRABQKpNZUtLTCL#scrollTo=uJgpmXoECjVo)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "metadata": {
        "id": "V_UpPsP2tVL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒŸ Gradio in Colab: Build Interactive AI Applications with Ease\n",
        "\n",
        "**Gradio** is an open-source library that allows you to create beautiful and easy-to-use user interfaces for machine learning models and data science apps directly from Python. ðŸŽ¨ Now, you can effortlessly run **Gradio interfaces** in **Google Colab** with just a few simple commands. ðŸš€\n",
        "\n",
        "âœ¨ **Key Features**:  \n",
        "- Build interactive web apps with minimal code, including image, text, and audio inputs.  \n",
        "- Integrate seamlessly with machine learning models from libraries like OpenAI, Hugging Face, and more.  \n",
        "- Share your models with others via quick deployment using `gr.Interface`.  \n",
        "- Ideal for creating demos, user testing, or showcasing AI models. ðŸ¤–  \n"
      ],
      "metadata": {
        "id": "__ddiZ-Kt1YQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Setup and Installation**"
      ],
      "metadata": {
        "id": "E1DFfMbGuEAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community langchain_openai  google-search-results gradio openai_gradio"
      ],
      "metadata": {
        "id": "uJgpmXoECjVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Image Generation with Gradio**"
      ],
      "metadata": {
        "id": "2q926MBBuO6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gradio import ChatMessage\n",
        "from transformers import Tool, ReactCodeAgent  # type: ignore\n",
        "from transformers.agents import stream_to_gradio, HfApiEngine  # type: ignore\n",
        "from dataclasses import asdict\n",
        "import os\n",
        "\n",
        "# Import tool from Hub\n",
        "image_generation_tool = Tool.from_space(\n",
        "    space_id=\"black-forest-labs/FLUX.1-schnell\",\n",
        "    name=\"image_generator\",\n",
        "    description=\"Generates an image following your prompt. Returns a PIL Image.\",\n",
        "    api_name=\"/infer\",\n",
        ")\n",
        "# Get the access token from environment variable\n",
        "access_token = os.environ.get(\"HUGGINGFACE_HUB_TOKEN\")\n",
        "if access_token:\n",
        "    llm_engine = HfApiEngine(\"Qwen/Qwen2.5-Coder-32B-Instruct\", token = access_token)\n",
        "else:\n",
        "    llm_engine = HfApiEngine(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
        "# Initialize the agent with both tools and engine\n",
        "agent = ReactCodeAgent(tools=[image_generation_tool], llm_engine=llm_engine)\n",
        "def interact_with_agent(prompt, history):\n",
        "    messages = []\n",
        "    yield messages\n",
        "    for msg in stream_to_gradio(agent, prompt):\n",
        "        messages.append(asdict(msg))\n",
        "        yield messages\n",
        "    yield messages\n",
        "\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    interact_with_agent,\n",
        "    chatbot= gr.Chatbot(\n",
        "        label=\"Agent\",\n",
        "        type=\"messages\",\n",
        "        avatar_images=(\n",
        "            None,\n",
        "            \"https://em-content.zobj.net/source/twitter/53/robot-face_1f916.png\",\n",
        "        ),\n",
        "    ),\n",
        "    examples=[\n",
        "        [\"Generate an image of an astronaut riding an alligator\"],\n",
        "        [\"I am writing a children's book for my daughter. Can you help me with some illustrations?\"],\n",
        "    ],\n",
        "    type=\"messages\",\n",
        ")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "id": "anaQHuo-Aglj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Real Time Speech Recognition with Gradio**"
      ],
      "metadata": {
        "id": "fJ7ElHmPtslB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "\n",
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
        "\n",
        "def transcribe(stream, new_chunk):\n",
        "    sr, y = new_chunk\n",
        "\n",
        "    # Convert to mono if stereo\n",
        "    if y.ndim > 1:\n",
        "        y = y.mean(axis=1)\n",
        "\n",
        "    y = y.astype(np.float32)\n",
        "    y /= np.max(np.abs(y))\n",
        "\n",
        "    if stream is not None:\n",
        "        stream = np.concatenate([stream, y])\n",
        "    else:\n",
        "        stream = y\n",
        "    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    transcribe,\n",
        "    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n",
        "    [\"state\", \"text\"],\n",
        "    live=True,\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "qQAhxVnTta37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Different Gradio Examples"
      ],
      "metadata": {
        "id": "iJj3ti5BDHMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Input Example**\n"
      ],
      "metadata": {
        "id": "rUo16vMrufPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def echo_input(text: str) -> str:\n",
        "    return f\"You entered: {text}\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    text_input = gr.Textbox(label=\"Enter some text\")\n",
        "    text_output = gr.Textbox(label=\"Output\")\n",
        "    text_input.change(echo_input, inputs=text_input, outputs=text_output)\n",
        "\n",
        "# Launch the app\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "q5kUq8Wje4fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Button with Action Example**\n"
      ],
      "metadata": {
        "id": "Bx8y_0xYuh1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def button_action() -> str:\n",
        "    return \"Button clicked!\"\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    button = gr.Button(\"Click Me!\")\n",
        "    message = gr.Textbox(label=\"Message\")\n",
        "\n",
        "    button.click(fn=button_action, outputs=message)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "52uJWFpagDfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dropdown for Recipe Selection**\n"
      ],
      "metadata": {
        "id": "iRIj4dqRuk5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def show_recipe(recipe: str) -> str:\n",
        "    recipes = {\n",
        "        \"Spaghetti\": \"Spaghetti with marinara sauce.\",\n",
        "        \"Salad\": \"Mixed greens with vinaigrette.\",\n",
        "        \"Soup\": \"Chicken soup with vegetables.\"\n",
        "    }\n",
        "    return recipes.get(recipe, \"Recipe not found\")\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    recipe_dropdown = gr.Dropdown(choices=[\"Spaghetti\", \"Salad\", \"Soup\"], label=\"Select a Recipe\")\n",
        "    recipe_output = gr.Textbox(label=\"Recipe Details\")\n",
        "\n",
        "    recipe_dropdown.change(show_recipe, inputs=recipe_dropdown, outputs=recipe_output)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "5T_SvjgFgmsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Area Example for Larger Input**\n"
      ],
      "metadata": {
        "id": "CDkkBen_upIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def display_large_text(text: str) -> str:\n",
        "    return f\"You entered:\\n{text}\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    text_area = gr.Textbox(lines=5, placeholder=\"Enter a recipe description\", label=\"Recipe Description\")\n",
        "    output_text = gr.Textbox(label=\"Entered Text\")\n",
        "\n",
        "    text_area.change(display_large_text, inputs=text_area, outputs=output_text)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "lzqAltkdg03T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **File Upload and Display Content Example**\n"
      ],
      "metadata": {
        "id": "amgBB7PZusiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def read_file(file) -> str:\n",
        "    with open(file.name, \"r\") as f:\n",
        "        content = f.read()\n",
        "    return content\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    file_input = gr.File(label=\"Upload your file\")\n",
        "    file_output = gr.Textbox(label=\"File Content\")\n",
        "\n",
        "    file_input.change(fn=read_file, inputs=file_input, outputs=file_output)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "dpr_NTe-ieJq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}