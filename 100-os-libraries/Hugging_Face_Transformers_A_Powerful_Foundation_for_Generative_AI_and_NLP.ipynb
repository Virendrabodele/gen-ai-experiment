{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1103aStq_C1yl6aNZuuqwUfgpalEoIXcd?usp=sharing)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "metadata": {
        "id": "8fEtdt_aoWQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒŸ **Hugging Face Transformers**: A Powerful Foundation for Generative AI and NLP\n",
        "Hugging Face Transformers is an open-source library designed for state-of-the-art Natural Language Processing (NLP) and Generative AI (GenAI) tasks, leveraging the power of transformer-based models. ðŸš€\n",
        "\n",
        "## âœ¨ **Key Features for GenAI and NLP**:\n",
        "\n",
        "- **Pre-trained Models**: Offers a diverse collection of pre-trained transformer models, including powerful generative architectures like GPT, BART, and T5, alongside models like BERT for other NLP tasks.\n",
        "  \n",
        "- **Core GenAI Tasks**: Features out-of-the-box support for core GenAI tasks like text generation, as well as other NLP tasks like classification, translation, summarization, and question answering.\n",
        "  \n",
        "- **Tools for Managing LLMs**: Offers tools for managing and optimizing large language models (LLMs) used in advanced GenAI scenarios. ðŸ“š"
      ],
      "metadata": {
        "id": "9yavnAFsoZOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Setup and Installation**"
      ],
      "metadata": {
        "id": "OmgIvYRppNWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bWj4Y03hL8w"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Text Classification**"
      ],
      "metadata": {
        "id": "VnSioZY7pRZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "result = classifier(\"This movie was absolutely fantastic!\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH4JTnenmGue",
        "outputId": "134bad13-ac04-4c73-c71f-df2efd2f1906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.999874472618103}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Text Generation using GPT-2**"
      ],
      "metadata": {
        "id": "vyZBJf8tpUbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "input_text = \"In a shocking turn of events, scientists discovered\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=100, temperature=0.7)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haOKOHzDmiPs",
        "outputId": "ecf927f9-26ef-44ac-c0f4-7f2b6baf14f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking turn of events, scientists discovered that the bacteria that cause the bacteria to grow in the gut are actually the same bacteria that cause the bacteria to grow in the brain.\n",
            "\n",
            "The researchers found that the bacteria that cause the bacteria to grow in the brain are actually the same bacteria that cause the bacteria to grow in the brain.\n",
            "\n",
            "The researchers found that the bacteria that cause the bacteria to grow in the brain are actually the same bacteria that cause the bacteria to grow in the brain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Named Entity Recognition (NER)**"
      ],
      "metadata": {
        "id": "kptKN8xOpald"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "result = ner(\"Hugging Face is a company based in New York City.\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZm8Agwhmt_-",
        "outputId": "11121983-21cc-4f3b-e399-cd57de317941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'B-ORG', 'score': 0.88835627, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}, {'entity': 'I-ORG', 'score': 0.9137654, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}, {'entity': 'I-ORG', 'score': 0.9774943, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}, {'entity': 'B-LOC', 'score': 0.9995097, 'index': 9, 'word': 'New', 'start': 35, 'end': 38}, {'entity': 'I-LOC', 'score': 0.9993987, 'index': 10, 'word': 'York', 'start': 39, 'end': 43}, {'entity': 'I-LOC', 'score': 0.99958295, 'index': 11, 'word': 'City', 'start': 44, 'end': 48}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Translation**"
      ],
      "metadata": {
        "id": "kndNFle3peHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
        "result = translator(\"Hello world!\", max_length=40)\n",
        "print(result[0]['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzMnpY4-mw8n",
        "outputId": "fc960673-1dca-48ce-fb8a-6a661c9dd985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hallo Welt!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Question Answering**"
      ],
      "metadata": {
        "id": "8boal3QlpiSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "context = \"\"\"Hugging Face is a company based in New York...\"\"\"\n",
        "question = \"Where is Hugging Face based?\"\n",
        "result = qa(question=question, context=context)\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbG0TKMnm_Wt",
        "outputId": "94805471-c408-4bdb-9df0-fe80d43b505b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New York\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Using Pipelines**"
      ],
      "metadata": {
        "id": "zpDkm98Lpn2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "vision_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "result = vision_classifier(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvoPo9xbqHiQ",
        "outputId": "7ec389e1-bad7-46c5-b9e9-41d6feee26c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Fine-Tuning a Model**"
      ],
      "metadata": {
        "id": "dh9QOc8Krz9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "# Prepare dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "# Training setup\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "LFSQyVRun27j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Custom Model & Tokenizer**"
      ],
      "metadata": {
        "id": "ym1xaZekr8wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
        "\n",
        "config = AutoConfig.from_pretrained(\"bert-base-uncased\")\n",
        "config.num_labels = 10\n",
        "\n",
        "model = AutoModel.from_config(config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "No4qA0AaoE_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}