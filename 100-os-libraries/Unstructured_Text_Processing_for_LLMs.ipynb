{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFsPqhN5KouZ"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mzjhMj6Za2EgFGjsXnuvw8LRMfQpsaS1?usp=sharing)\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "id": "ZFsPqhN5KouZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D88aQIkKouf"
      },
      "source": [
        "## Overview of Unstructured üìö\n",
        "\n",
        "Unstructured is an open-source library designed to easily preprocess text documents for LLM applications. üöÄ It helps you extract, clean, and structure text from various file types, making it suitable for feeding into Language Models.\n",
        "\n",
        "**Key Features:** ‚ú®\n",
        "\n",
        "- **Multi-format Support:** Handles PDFs, Word documents, HTML, and more. üìÑ\n",
        "- **Text Extraction:** Extracts text from documents while preserving document structure. üìù\n",
        "- **Data Cleaning:** Cleans and normalizes text for better LLM performance. üßπ\n",
        "- **Element Chunking:** Breaks down text into meaningful chunks. üß©\n",
        "- **Easy Integration:** Integrates seamlessly with LangChain and other LLM frameworks. ü§ù"
      ],
      "id": "1D88aQIkKouf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMscoLDZKouh"
      },
      "source": [
        "### üì¶ **Dependency Installation**"
      ],
      "id": "TMscoLDZKouh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEL_KCQjKouh"
      },
      "outputs": [],
      "source": [
        "# Install the Unstructured library\n",
        "!pip install unstructured[pdf] langchain_community chromadb tiktoken"
      ],
      "id": "TEL_KCQjKouh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup API Keys\n"
      ],
      "metadata": {
        "id": "l2RKE0q4SiwE"
      },
      "id": "l2RKE0q4SiwE"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] =userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "8pOrfV0aRP0N"
      },
      "id": "8pOrfV0aRP0N",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVW_yA1bKouj"
      },
      "source": [
        "### üìú **Basic Text Extraction from a PDF**"
      ],
      "id": "XVW_yA1bKouj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNkKFdVhKouk"
      },
      "outputs": [],
      "source": [
        "from unstructured.partition.auto import partition\n",
        "import requests\n",
        "\n",
        "# Example PDF URL (replace with a public PDF URL)\n",
        "pdf_url = \"https://arxiv.org/pdf/2310.06825.pdf\" # Example:  a research paper\n",
        "\n",
        "# Download the PDF\n",
        "response = requests.get(pdf_url)\n",
        "with open(\"example.pdf\", \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Partition the PDF\n",
        "elements = partition(filename=\"example.pdf\")\n",
        "\n",
        "# Print the extracted text\n",
        "for element in elements:\n",
        "    print(element.text)\n"
      ],
      "id": "jNkKFdVhKouk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znJGbp5fKouk"
      },
      "source": [
        "### üìÑ **Extracting text from a local .txt file**"
      ],
      "id": "znJGbp5fKouk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3URX5DgxKoul",
        "outputId": "2e8dfe8f-73b0-4b46-f4d5-38cb21bf1c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sample text file.\n",
            "It contains multiple lines of text.\n",
            "Unstructured can process this easily.\n"
          ]
        }
      ],
      "source": [
        "from unstructured.partition.text import partition_text\n",
        "\n",
        "# Create a dummy text file\n",
        "with open(\"dummy_text.txt\", \"w\") as f:\n",
        "    f.write(\"This is a sample text file.\\n\")\n",
        "    f.write(\"It contains multiple lines of text.\\n\")\n",
        "    f.write(\"Unstructured can process this easily.\")\n",
        "\n",
        "# Partition the text file\n",
        "elements = partition_text(filename=\"dummy_text.txt\")\n",
        "\n",
        "# Print the extracted text\n",
        "for element in elements:\n",
        "    print(element.text)"
      ],
      "id": "3URX5DgxKoul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aACRCs-vKoul"
      },
      "source": [
        "### üåê **Extracting text from a website URL**"
      ],
      "id": "aACRCs-vKoul"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWjuUK9YKoum"
      },
      "outputs": [],
      "source": [
        "from unstructured.partition.html import partition_html\n",
        "import requests\n",
        "\n",
        "# Fetch HTML content from a URL\n",
        "url = \"https://www.unstructured.io/\"\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "# Partition the HTML\n",
        "elements = partition_html(text=html_content)\n",
        "\n",
        "# Print the extracted text\n",
        "for element in elements:\n",
        "    print(element.text)"
      ],
      "id": "DWjuUK9YKoum"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üåê Vector database ingestion\n",
        "\n"
      ],
      "metadata": {
        "id": "PqiXC62eN1I2"
      },
      "id": "PqiXC62eN1I2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this guide, we demonstrate how to leverage Unstructured.IO, ChromaDB, and LangChain to summarize topics from the front page of CNN Lite. Utilizing the modern LLM stack, including Unstructured, Chroma, and LangChain, this workflow is streamlined to less than two dozen lines of code."
      ],
      "metadata": {
        "id": "WzW_H1LMSUp-"
      },
      "id": "WzW_H1LMSUp-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gather Links with Unstructured"
      ],
      "metadata": {
        "id": "aBUISr2yR_UD"
      },
      "id": "aBUISr2yR_UD"
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.html import partition_html\n",
        "\n",
        "cnn_lite_url = \"https://lite.cnn.com/\"\n",
        "elements = partition_html(url=cnn_lite_url)\n",
        "links = []\n",
        "\n",
        "for element in elements:\n",
        "    if element.metadata.link_urls:\n",
        "        relative_link = element.metadata.link_urls[0][1:]\n",
        "        if relative_link.startswith(\"2025\"):\n",
        "            links.append(f\"{cnn_lite_url}{relative_link}\")"
      ],
      "metadata": {
        "id": "Bq7VbSbkN1-H"
      },
      "id": "Bq7VbSbkN1-H",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ingest Individual Articles with UnstructuredURLLoader\n"
      ],
      "metadata": {
        "id": "kK8NTOjiSFas"
      },
      "id": "kK8NTOjiSFas"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "\n",
        "loaders = UnstructuredURLLoader(urls=links, show_progress_bar=True)\n",
        "docs = loaders.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wjt4aL5RArO",
        "outputId": "32ee4a8c-fc70-4aba-f423-49bfed070c83"
      },
      "id": "-Wjt4aL5RArO",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:29<00:00,  3.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Documents into ChromaDB\n"
      ],
      "metadata": {
        "id": "W9aSUrnzSIRe"
      },
      "id": "W9aSUrnzSIRe"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(docs, embeddings)\n",
        "query_docs = vectorstore.similarity_search(\"Update on the coup in Niger.\", k=1)"
      ],
      "metadata": {
        "id": "9DxD3nhLRHUu"
      },
      "id": "9DxD3nhLRHUu",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summarize the Documents\n"
      ],
      "metadata": {
        "id": "cA73jnqgSOIj"
      },
      "id": "cA73jnqgSOIj"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "chain.run(query_docs)"
      ],
      "metadata": {
        "id": "zI-wWIlfRXjy"
      },
      "id": "zI-wWIlfRXjy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}