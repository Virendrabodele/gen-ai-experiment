{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1s5CMSEyiDHnH5XS0cHBypcmE5Dn9TYoa?usp=sharing)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "metadata": {
        "id": "j9jmsKue__AN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçÉ MongoDB for AI-Powered Applications üöÄ  \n",
        "\n",
        "MongoDB is a **NoSQL** database designed for handling large-scale, high-performance applications. ‚ö° With its flexible document model and powerful querying capabilities, it's an excellent choice for AI-driven workflows. ü§ñüí°  \n",
        "\n",
        "## üî• Why Use MongoDB?  \n",
        "\n",
        "‚úÖ **Flexible Document Storage:** üìÑ Store structured & unstructured data efficiently.  \n",
        "‚úÖ **Vector Search:** üß†üîé Ideal for handling embeddings and similarity searches.  \n",
        "‚úÖ **Real-Time Processing:** ‚ö° Supports high-speed data retrieval and updates.  \n",
        "‚úÖ **Scalable & Fast:** üöÄ Handles large-scale applications with ease.  \n",
        "‚úÖ **Seamless Integration:** üîó Works well with AI frameworks like PyTorch, TensorFlow, and LangChain.  \n",
        "‚úÖ **Cloud & Local Support:** ‚òÅÔ∏è Run on MongoDB Atlas (cloud) or locally.  \n"
      ],
      "metadata": {
        "id": "QyHUQP29_-3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üì¶ Install Required Packages**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oQJXHXcP_-rq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_vZpVm9us5H"
      },
      "outputs": [],
      "source": [
        "!pip install pymongo\n",
        "!pip install pymongo langchain tiktoken faiss-cpu pypdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîë Setup API Keys**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jJEtcq1tA0iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "MONGODB_URI = userdata.get('MONGODB_URI')"
      ],
      "metadata": {
        "id": "6p3XR_-TvZt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîó Check Connection**\n"
      ],
      "metadata": {
        "id": "EYB5kaNpAgc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "connection_string = MONGODB_URI\n",
        "\n",
        "client = MongoClient(connection_string)\n",
        "client.admin.command('ping')\n",
        "print(\"‚úÖ Connected to MongoDB Atlas successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_wHAAchvjiP",
        "outputId": "1e3c7926-6109-4db6-faa1-1bcd750fc408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Connected to MongoDB Atlas successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üóÑÔ∏è Create a Database and Collection**\n"
      ],
      "metadata": {
        "id": "nm2cpas1AJhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = client[\"my_database\"]\n",
        "collection = db[\"users\"]\n"
      ],
      "metadata": {
        "id": "c929ZjDZ_fMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚ûï Insert One Document**\n"
      ],
      "metadata": {
        "id": "aY_D6wyPAKp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = {\"name\": \"John Doe\", \"age\": 30, \"city\": \"New York\"}\n",
        "collection.insert_one(user)\n",
        "print(\"‚úÖ One document inserted!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYrZbF6I_kt2",
        "outputId": "a472f13a-dffb-4616-f946-c588437408cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ One document inserted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìÇ Insert Multiple Documents**\n"
      ],
      "metadata": {
        "id": "T7oqcIvzANJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users = [\n",
        "    {\"name\": \"Alice\", \"age\": 25, \"city\": \"Los Angeles\"},\n",
        "    {\"name\": \"Bob\", \"age\": 28, \"city\": \"Chicago\"},\n",
        "]\n",
        "collection.insert_many(users)\n",
        "print(\"‚úÖ Multiple documents inserted!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WzMmEO0_mxC",
        "outputId": "abd52921-a407-4c66-b0a3-ef68897703f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Multiple documents inserted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîç Find One Document**\n"
      ],
      "metadata": {
        "id": "HXaEjHDHAPZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = collection.find_one({\"name\": \"John Doe\"})\n",
        "print(\"üë§ Found user:\", user)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQPvMq3Q_p0F",
        "outputId": "2519e5e1-bfda-409a-bdf5-e417de71f76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üë§ Found user: {'_id': ObjectId('67b0e4f9385ffc37fdc11fa7'), 'name': 'John Doe', 'age': 30, 'city': 'New York'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìã Find All Documents**\n"
      ],
      "metadata": {
        "id": "Y8-bQDdCARxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for user in collection.find():\n",
        "    print(user)\n"
      ],
      "metadata": {
        "id": "fWGjpXWZ_sBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üéØ Find Documents with a Condition**\n"
      ],
      "metadata": {
        "id": "4zQAtmqMATvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for user in collection.find({\"city\": \"New York\"}):\n",
        "    print(user)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9KIzTZc_vMv",
        "outputId": "02da54b3-5879-46d1-c89c-567559104c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': ObjectId('67b0e4f9385ffc37fdc11fa7'), 'name': 'John Doe', 'age': 30, 'city': 'New York'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚úèÔ∏è Update One Document**\n"
      ],
      "metadata": {
        "id": "wMOM24YnAVyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.update_one({\"name\": \"John Doe\"}, {\"$set\": {\"age\": 31}})\n",
        "print(\"‚úÖ User updated!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVXIMJXA_yWK",
        "outputId": "aa3dc2f2-468e-4d89-d031-435f786fb577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ User updated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚ùå Delete One Document**\n"
      ],
      "metadata": {
        "id": "2b1zk_sTAXu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.delete_one({\"name\": \"Alice\"})\n",
        "print(\"‚úÖ One document deleted!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oZ7Xi7B_0kv",
        "outputId": "6516079e-c4db-4707-9432-204746fdc2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ One document deleted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚ö†Ô∏è Drop Collection (Delete Everything)**\n"
      ],
      "metadata": {
        "id": "8QZiGNmXAbss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.drop()\n",
        "print(\"üóëÔ∏è Collection deleted!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8mdGA-P_5x_",
        "outputId": "f050a8da-d4d2-4654-a4d7-84cef47de3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üóëÔ∏è Collection deleted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ü§ñ Performing RAG (Retrieval-Augmented Generation) with MongoDB**"
      ],
      "metadata": {
        "id": "RTE9t_5KBift"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from pymongo.operations import SearchIndexModel\n",
        "import time\n",
        "from typing import List, Dict\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n"
      ],
      "metadata": {
        "id": "MaJIgcxS7e6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üóÑÔ∏è Create Database and Collection**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j5EVqZFbBnKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = client.mydatabase\n",
        "\n",
        "collection = db.mycollection"
      ],
      "metadata": {
        "id": "8G3VCgWf90qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üß† Generate Embeddings with OpenAI**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "huBEta8ABq46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "def get_embedding(text: str) -> List[float]:\n",
        "    return embeddings.embed_query(text)"
      ],
      "metadata": {
        "id": "hBFg6rov95_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üìÑ Load PDF Document from URL**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Juc1uuicBvOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_url = \"https://investors.mongodb.com/node/12236/pdf\"\n",
        "loader = PyPDFLoader(pdf_url)\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "s8igp30N9_65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚úÇÔ∏è Split Text into Chunks**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c_K7V3ylBy4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
        "documents = text_splitter.split_documents(data)\n",
        "print(f\"Loaded and split {len(documents)} documents from PDF.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe0Sa-6O-JZn",
        "outputId": "8530d198-6309-4782-b927-b691b779aafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and split 88 documents from PDF.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üì• Generate and Store Embeddings in MongoDB**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PWxJV1kXB22U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_to_insert: List[Dict] = []\n",
        "for doc in documents:\n",
        "    try:\n",
        "        embedding = get_embedding(doc.page_content)\n",
        "        docs_to_insert.append({\n",
        "            \"text\": doc.page_content,\n",
        "            \"embedding\": embedding\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding for chunk: {e}\")\n",
        "\n",
        "if docs_to_insert:\n",
        "    result = collection.insert_many(docs_to_insert)\n",
        "    print(f\"Inserted {len(docs_to_insert)} documents into MongoDB\")\n",
        "else:\n",
        "    print(\"No documents to insert.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bLBgbNE-MXt",
        "outputId": "eb98fd12-3dc9-4d20-b66a-8e2fce8c6b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 88 documents into MongoDB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîç Create Vector Search Index in MongoDB**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9t0JFcoeB7_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"vector_index\"\n",
        "search_index_model = SearchIndexModel(\n",
        "    definition={\n",
        "        \"fields\": [\n",
        "            {\n",
        "                \"type\": \"vector\",\n",
        "                \"numDimensions\": 1536,\n",
        "                \"path\": \"embedding\",\n",
        "                \"similarity\": \"cosine\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    name=index_name,\n",
        "    type=\"vectorSearch\"\n",
        ")\n",
        "try:\n",
        "    collection.create_search_index(model=search_index_model)\n",
        "    print(f\"Created vector search index '{index_name}' on MongoDB collection.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating index: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMLTNKbk-Kfv",
        "outputId": "95ce255d-7bf2-4dc8-89f3-8c08bee4fefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created vector search index 'vector_index' on MongoDB collection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚è≥ Wait for Vector Search Index to be Ready**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l00FMFNpCBoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
        "predicate = None\n",
        "if predicate is None:\n",
        "   predicate = lambda index: index.get(\"queryable\") is True\n",
        "while True:\n",
        "   indices = list(collection.list_search_indexes(index_name))\n",
        "   if len(indices) and predicate(indices[0]):\n",
        "      break\n",
        "   time.sleep(5)\n",
        "print(index_name + \" is ready for querying.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a3XE_eA-SJB",
        "outputId": "4ba1d2f2-030b-4cbe-ef76-4a278f4eb838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polling to check if the index is ready. This may take up to a minute.\n",
            "vector_index is ready for querying.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üîé Define Function for Vector Search Queries**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zbwx00SrCAlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_query_results(query: str, limit: int = 5) -> List[Dict]:\n",
        "    \"\"\"Gets results from a vector search query.\"\"\"\n",
        "    query_embedding = get_embedding(query)\n",
        "    pipeline = [\n",
        "        {\n",
        "            \"$vectorSearch\": {\n",
        "                \"index\": index_name,\n",
        "                \"queryVector\": query_embedding,\n",
        "                \"path\": \"embedding\",\n",
        "                \"numCandidates\": 10,\n",
        "                \"limit\": limit,\n",
        "            }\n",
        "        },\n",
        "        {\"$project\": {\"_id\": 0, \"text\": 1}}\n",
        "    ]\n",
        "    results = list(collection.aggregate(pipeline))\n",
        "    return results"
      ],
      "metadata": {
        "id": "_OYVl9sc-ZGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üí¨ Perform Retrieval and Question Answering**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v0yxGCGSCIfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are MongoDB's latest AI announcements?\"\n",
        "results = get_query_results(query)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Results:\")\n",
        "for doc in results:\n",
        "    print(doc)"
      ],
      "metadata": {
        "id": "M603K9yV-W8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üß† Generate Answer Using Retrieved Context**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pZVignQkCM_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are MongoDB's latest AI announcements?\"\n",
        "results = get_query_results(query)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Results:\")\n",
        "for doc in results:\n",
        "    print(doc)\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "context_string = \" \".join([doc[\"text\"] for doc in results])\n",
        "\n",
        "prompt = f\"\"\"Use the following pieces of context to answer the question at the end.\n",
        "    {context_string}\n",
        "    Question: {query}\n",
        "\"\"\"\n",
        "output = llm(prompt)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPcUAqzV-dXt",
        "outputId": "beb2e78a-97a4-4f8f-904c-c73496cbbc87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are MongoDB's latest AI announcements?\n",
            "Results:\n",
            "{'text': 'MongoDB  continues to expand its AI ecosystem with the announcement of the MongoDB AI Applications Program (MAAP),'}\n",
            "{'text': 'more of our customers. We also see a tremendous opportunity to win more legacy workloads, as AI has now become a catalyst to modernize these\\napplications. MongoDB\\'s document-based architecture is particularly well-suited for the variety and scale of data required by AI-powered applications.\\xa0\\nWe are confident MongoDB  will be a substantial beneficiary of this next wave of application development.\"'}\n",
            "{'text': 'which provides customers with reference architectures, pre-built partner integrations, and professional services to help\\nthem quickly build AI-powered applications. Accenture will establish a center of excellence focused on MongoDB  projects,\\nand is the first global systems integrator to join MAAP.'}\n",
            "{'text': 'of MongoDB  8.0‚Äîwith significant performance improvements such as faster reads and updates, along with significantly\\nfaster bulk inserts and time series queries‚Äîand the general availability of Atlas Stream Processing to build sophisticated,\\nevent-driven applications with real-time data.'}\n",
            "{'text': 'Bendigo and Adelaide Bank partnered with MongoDB  to modernize their core banking technology. With the help of\\nMongoDB Relational Migrator and generative AI-powered modernization tools, Bendigo and Adelaide Bank decomposed an\\noutdated consumer-servicing application into microservices and migrated off its underlying legacy relational database'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-fb4487e4f3f2>:26: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  output = llm(prompt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MongoDB's latest AI announcements include the MongoDB AI Applications Program (MAAP), the release of MongoDB 8.0 with performance improvements, the general availability of Atlas Stream Processing, and a partnership with Accenture to establish a center of excellence focused on MongoDB projects.\n"
          ]
        }
      ]
    }
  ]
}