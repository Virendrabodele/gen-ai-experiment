{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee8b7ec41b5f47e0b122c6f208225c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_616050f2ed7843a3ad748f076748aae7",
              "IPY_MODEL_75d04b58aabc4942acb57f419e3745f2",
              "IPY_MODEL_3ab91e0b261d40e6ad388176243e4254"
            ],
            "layout": "IPY_MODEL_ed0fc5959a9e44aca6f156a2e232c627"
          }
        },
        "616050f2ed7843a3ad748f076748aae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d4b7c13ede4d8ab50dc7e05d278d5b",
            "placeholder": "​",
            "style": "IPY_MODEL_7135dd96d0004aff8317d29aa60dd978",
            "value": ""
          }
        },
        "75d04b58aabc4942acb57f419e3745f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0131252772fa4a1fa03b48ea51ac1270",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6365d100c204588b26fe036e35ba16b",
            "value": 1
          }
        },
        "3ab91e0b261d40e6ad388176243e4254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e8a033fa4b41b096b95bb0252c24f2",
            "placeholder": "​",
            "style": "IPY_MODEL_85a28d63ee724726a8899d7100d6d1a4",
            "value": "Loading pt checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  4.56it/s]\n"
          }
        },
        "ed0fc5959a9e44aca6f156a2e232c627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d4b7c13ede4d8ab50dc7e05d278d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7135dd96d0004aff8317d29aa60dd978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0131252772fa4a1fa03b48ea51ac1270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6365d100c204588b26fe036e35ba16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2e8a033fa4b41b096b95bb0252c24f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a28d63ee724726a8899d7100d6d1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "932e86e395bc4f228e3c9b79c7d44918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_776b318f584c4b5bafc2c75a91b95c39",
              "IPY_MODEL_2f990482a3264256aab6eddd046320d3",
              "IPY_MODEL_f5152298674343c9aa1d08745aaa261c"
            ],
            "layout": "IPY_MODEL_f43ce55c856b493c965243a1d7e02ef2"
          }
        },
        "776b318f584c4b5bafc2c75a91b95c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b336e66e62bc4238b085f8f384a609e7",
            "placeholder": "​",
            "style": "IPY_MODEL_292b4bab51294ed29efdb2b9e4701223",
            "value": ""
          }
        },
        "2f990482a3264256aab6eddd046320d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2a0ddc7871b463487f3cc64d26e3ee2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b4aa9f22e824c5eb48b168ab6ca671f",
            "value": 1
          }
        },
        "f5152298674343c9aa1d08745aaa261c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee83fe532a64f03a9c62a0d7d963a3a",
            "placeholder": "​",
            "style": "IPY_MODEL_f698ff91a7e94588854d49161ca3c848",
            "value": "Loading pt checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  5.11it/s]\n"
          }
        },
        "f43ce55c856b493c965243a1d7e02ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b336e66e62bc4238b085f8f384a609e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292b4bab51294ed29efdb2b9e4701223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2a0ddc7871b463487f3cc64d26e3ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b4aa9f22e824c5eb48b168ab6ca671f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ee83fe532a64f03a9c62a0d7d963a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f698ff91a7e94588854d49161ca3c848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1qq07ZvtaLGVl94kN0SkWK6B4HkTN15jk?usp=sharing)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ],
      "metadata": {
        "id": "fCZ4DpKsfzTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🚀 vLLM_Fast_LLM_Inference ⚡\n",
        "\n",
        "vLLM is a super-fast 🏎️ and easy-to-use library for LLM (Large Language Model) inference. 🧠💨 It's designed to make running those big models much more efficient. ✨\n",
        "\n",
        "## 🚀 Key Features\n",
        "\n",
        "✅ **Lightning Fast:** ⚡️ Optimized for high-throughput inference.  \n",
        "✅ **Memory Efficient:** 🧠💪 Runs large models with less GPU memory.  \n",
        "✅ **Easy to Use:** 🛠️ Simple API for generating text.  \n",
        "✅ **Batch Processing:** 📦 Processes multiple prompts in parallel.  \n",
        "✅ **Streaming Support:** 🌊 Generates text in real-time.  \n",
        "✅ **Open Source:** 💻 Fully transparent and free to use.\n"
      ],
      "metadata": {
        "id": "ctoQw186f0oA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🚀 Installation & Setup**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iqANZLrOf01a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm"
      ],
      "metadata": {
        "id": "1KnR3pQsdXqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🧠🚀 vLLM Model Initialization and Sampling**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WcOiaBSWnLt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams"
      ],
      "metadata": {
        "id": "tGC3irahfJWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🤖🚀 Loading vLLM Model (OPT-125M)**\n"
      ],
      "metadata": {
        "id": "lNpCbohsoWmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = LLM(model=\"facebook/opt-125m\")"
      ],
      "metadata": {
        "id": "ZiHRGxxifKMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🎯🔥 Setting Sampling Parameters**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "keYXflqeob42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=256)"
      ],
      "metadata": {
        "id": "-zw6Bs9ufajd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **📝🤖 Generating Text with vLLM**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dDMx_79Yoe9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Hello, my name is\",\n",
        "    \"The capital of France is\",\n",
        "    \"The future of AI is\",\n",
        "]\n",
        "\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLQXct2NfdJ0",
        "outputId": "66111e81-6bd7-49a6-97d4-8388014c0279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 3/3 [00:01<00:00,  2.77it/s, est. speed input: 16.65 toks/s, output: 710.25 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'Hello, my name is', Generated text: \" Joel, my dad is my friend and we are in a relationship. I am from Gaviota, Greece and I am doing a video interview with a Greek TV show and you can watch this video about the relationship between me and my dad. I have lived in Greece for a few years now and I have seen many people have lived in Greece for a long time. I think the relationship between me and my father is very similar. The relationship between me and my father is very deep and deep. I am very happy to be the son of the Greek Prime Minister and I am very happy to live with my dad. My father and I are very close and my father is very happy to live with me. And I am very proud of my son. I am very happy about it.\\nI love my family and I will always be happy. I always loved my family. I never wanted to have a daughter. I am very happy to be the father of a daughter and I am very happy for my life. I want to live with my family. I want my life to be a good one. That's all I can do. I am happy with my life. I will always be happy with my life. And I love my family, I love my family.\"\n",
            "Prompt: 'The capital of France is', Generated text: ' at an impasse with the French government over its future as the euro zone’s biggest economy.\\n\\nThe French government has proposed extending the euro’s term from 18 years to 27 years, with the option of a further extension.\\n\\nFrance’s proposal would see the euro undergo four years of restructuring, or 12 years, under the current financial system, and the immediate fiscal break-up would be subject to the approval of France’s lawmakers.\\n\\nThe €47 billion ($58.1 billion) bailout deal agreed with the EU last week will carry over into the second half of 2016, while a third of its annual budget deficit would also be frozen, as part of the restructuring plan.\\n\\nFrench President Emmanuel Macron is set to decide whether to extend the European Union’s European Recovery Plan (EUROP) by another five years in a speech to the nation on Tuesday.\\n\\nA proposal by the centre-right government would see the euro’s current term extend by another year, from the end of 2015 to the end of the current fiscal year.\\n\\nThe ECB, which has all but pledged to continue its quantitative easing programme, is also considering extending its new bond-buying programme, which has'\n",
            "Prompt: 'The future of AI is', Generated text: \" now at the hands of AI.\\n\\nThe AI will now be the super-intelligent 'extremist' which seems to have the potential to eventually rule the world, in a globalised world, with its own kind of AI. The AI will now be the super-intelligent 'extremist' which seems to have the potential to eventually rule the world, in a globalised world, with its own kind of AI.\\n\\nThis is what AI can do.\\n\\nIt's how we can save lives and what we can do about it.\\n\\nWe could create an artificial intelligence of our own, in some way. We could design it to do a few things, like:\\n\\nIt could generate a lot of information about us, but it could do a lot of things, such as:\\n\\nIt could do a lot of things that aren't going to be useful in other ways, like:\\n\\nIt could do a lot of things that aren't going to be useful in other ways, like:\\n\\nIt could do a lot of things that are not going to be useful in other ways, like:\\n\\nIt could do a lot of things that aren't going to be useful in other ways, like:\\n\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🧠📜 Creating a Large Batch of Prompts**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bvhES0dBoiXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"What is the meaning of life?\",\n",
        "    \"Write a short story about a cat.\",\n",
        "    \"Translate 'hello' to Spanish.\",\n",
        "    \"What is the capital of Japan?\",\n",
        "    \"Explain the theory of relativity.\",\n",
        "    \"Write a poem about the ocean.\",\n",
        "    \"What is the highest mountain in the world?\",\n",
        "    \"Write a Python function to calculate the factorial of a number.\",\n",
        "] * 10"
      ],
      "metadata": {
        "id": "omT0ga7IffZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🚀📝 Generating and Displaying LLM Outputs**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GMpcqr7QongO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = llm.generate(prompts, sampling_params)\n",
        "\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n",
        "    print(\"Generated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LjuwhmufjjB",
        "outputId": "e6f00750-927a-42f9-bebb-6d6c0ba3ff40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 80/80 [00:02<00:00, 37.47it/s, est. speed input: 346.85 toks/s, output: 3708.88 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'What is the meaning of life?', Generated text: '\\n\\nLife is a line in the vernacular. It means that it was chosen by a Creator. All of us have a purpose. That purpose is to be born. We must be able to live from the inside. We must be able to live from inside.\\n\\nLife is what God created us to do.\\n\\nEverything that we do, it’s God created us to do. There’s nothing else in this world.\\n\\nThere’s nothing to do.\\n\\nNothing to be thankful for.\\n\\nEverything we do, it’s God created us to do. There’s nothing to be grateful for.\\n\\nEverything we do, it’s God created us to do. There’s nothing to be thankful for.\\n\\nEverything we do, it’s God created us to do. There’s nothing to be thankful for.\\n\\nEverything we do, it’s God created us to do. There’s nothing to be thankful for.\\n\\nEverything we do, it’s God created us to do. There’s nothing to be thankful for.\\n\\nEverything we do, it’s God created us to do'\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: '\\nthats gonna be fun!'\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: \" It's easy, but it's a bit boring.\\nThank you! I'll try to learn Spanish more easily.\"\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: \" The capital is Tokyo, but the capital is K-pop (Japan's national musical and dance group).\\nThe capital is Tokyo, but the capital is K-pop (Japan's national musical and dance group).  It's definitely not the greatest capital, but it's the closest to the city where my GF and I live. I prefer Tokyo for that reason, and I don't think we're that old.\\nThat's really cool to hear.  We have a romantic love affair with Japan, so it seems like there's lots of little Japanese treasures.\"\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: '\\nHow do you explain relativity?\\nbecause this is the general theory behind relativity'\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: \"\\nThis is something I've been thinking about, thank you!\\nThere are a bunch of different ways to write poems. I recommend Bechtel's Electric Poems, by Irving Berlin.\\nI've never heard of him but I'll definitely give it a read!\"\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: '\\n\\nI’m on a mountain in the middle of the US. The moon is blue with blue skies, so I can’t really see the mountains. But you can see the mountains.\\n\\nMy mother was born in the USA. She went to school in the USA and she was born in the USA. My mother was born in the USA and we have a common name, the Mountain. My mother was born in the USA. I was born in the USA and we have a common name, the Mountain. She was born in the USA and we have a common name, the Mountain.\\n\\nMy mother was born in the USA and we have a common name, the Mountain. She was born in the USA and we have a common name, the Mountain. She was born in the USA and we have a common name, the Mountain.\\n\\nI have a really complicated situation. I went to a school in the USA, and it’s a very small school, and it’s a very small school. I was a little bit scared.\\n\\nI had the time off from school, and I had a friend who was going to come and visit me in the USA, and he took me to the small school in'\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: '\\n- See the help page for more information.\\n- For example, a calculation may be performed to calculate the number of numbers in a given vector.\\n- For example, the sum of the number of pairs in a given vector may be multiplied by two and multiplied by three.\\n- For example, if a calculator calculates a pair of numbers, then it uses the sum of the pairs in the given vector to calculate the number of pairs in a given number.\\n- For example, if a calculator calculates a pair of numbers, then it uses the sum of the pairs in a given number to calculate the number of pairs in a given number.\\n- For example, if a calculator calculates a pair of numbers, then it uses the sum of the pairs in a given number to calculate the number of pairs in a given number.\\n- For example, if a calculator calculates a pair of numbers, then it uses the sum of the pairs in a given number to calculate the number of pairs in a given number.\\n- For example, if a calculator calculates a pair of numbers, then it uses the sum of the pairs in a given number to calculate the number of pairs in a given number.\\n- For example, if a calculator calculates a pair of numbers,'\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: '\\n\\nI am in the process of researching life and it seems to me that there are a lot of questions that people may be asking, and I think I’m beginning to figure it out. I’ve been asked about the meaning of life by a few different people, and I’ve come to the conclusion that it is a very specific question, and that I am going to answer it.\\n\\nWhat is life like?\\n\\nLife is a time of balance. I don’t think I’m a dog person. I am a human being, a human being. It’s a time to be together. It’s a time to be together, to be alive. It’s a time to be grateful. It’s a time to be thankful to God for allowing me to be a human being.\\n\\nWhat is your favorite thing about being a human being?\\n\\nI like to be with my family. I like to be with my husband and kids. I like to be with my family, and I like to be with my friends and neighbors. It is a time to be with my heart and I like to be with my friends and neighbors.\\n\\nWhat is your favorite'\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: \"\\nI'm actually writing a story about a cat with a cat in it, but I've never done it because I'm new to reddit, I'm just bored.\\nAs someone who reads many stories and often write about cats, I thought the same thing about you. :P\\nI really enjoyed reading your story and was wondering if you had any ideas on how to do it.  I'm kind of confused as to how to get started.  I mean, if I'm going to be writing about cats, I'd probably want to know how to make sure it isn't something I'm not interested in.  I know this isn't a personal question and I do hope that it does help.\\nI'm not sure about the best way, but I do think you should get started. I'm really into cat stories and I can't imagine writing a story about a cat or their behavior.\\nHave you ever written a story about a cat?  I'd love to hear what you have to say.\\nHonestly, I don't know how I would do it. I've never done anything about it, but I'm new to reddit. I guess I would need to find a way to get started?\\nWell, it's just a little story\"\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: ' It is done by linguist Ernesto de Soto.\\nThanks!  I figured it out.'\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: \"\\nJapan has a capital, though the most common capital is Tokyo (the capital of Japan).\\nPretty sure the capital is Tokyo.\\nCorrect. I'm not making a general generalization, I was just pointing out the fact that the capital of Japan is Tokyo.\"\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: \"\\nIf we are talking about a theory of relativity we are talking about how we can have a number of particles move at the same speed.\\nI don't think that explains it, it just shows that the speed of light isn't the only thing that matters.\\nI guess I meant we can have something like in our minds at any speed, but we have nothing to show for it.\"\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: '\\nAnd then you can make a song about the ocean.'\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: \"\\nEvelyn? I've been thinking about this.\"\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: ' It will probably have a few little red bars that say \"if X == 0, X is the number\" and then continue. But if you only want to read x, you can use \"if X == 0, X is the number\" to make it obvious that X is the number.\\n\\nMake a function which assumes that the number is zero because the number is zero and that x = 0. This can be interesting, as it suggests that the number is only zero since it doesn\\'t have any roots. It may seem like a difficult task to explain, but when you get it, the question becomes \"How does it work?\".\\n\\nIf you want to use this, you can replace the \"x = 0\" with \"x = 0\". This is true of x 0, and the numbers 0 and 0 are not the same as the numbers 1 and 2.\\n\\nThis is a good way to show that the number is zero.\\n\\nIf you want to use this, you can replace the \"x = 0\" with \"x = 0\". This is true of x 0, and the numbers 0 and 0 are not the same as the numbers 1 and 2.\\n\\nThis is a good way to show that the number is zero.\\n'\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: \" Do we have to be young to do it? Do we have to be famous to be good? Do we need to be expensive to have fun?\\nIt's not life if you're a fan.\"\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: \"\\nYou think that would be boring? I'd love to see that.\"\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: \" I can't speak for everyone, but I love talking to people outside of my native tongue and I'm a native speaker. It's a great time of year.\\nI was also thinking about this, but I live in a city where I don't speak Spanish so I don't know if it's a good idea to do that.\\nNo problem. I'm just saying that even when I was a kid I could understand some of it but when I did I was really forced to understand it in Spanish.   I'm also pretty bad with spelling, but I've gotten into some random words and they become slightly more precise. I'd say it's pretty useless to learn it in Spanish.\"\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: \" It looks like a 5th world country.\\nIt's actually a bit of a one-world country. Japan is the capital of that country, but most people aren't actually from there.  I know it's not like it's a 10 million year old city, but it's definitely the largest city of Japan.\"\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: \"\\nI don't know the theory.\"\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: \"  It can be tough to remember when the sun goes down, but you can use it as an inspiration.\\nI've been trying to write a poem about the ocean but I'm a bit lazy. Is there any kind of link to a course?\\nThere is a course on the ocean ocean.  It's a great book that might help you.\"\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: \"\\nThe peak of the mountain is 20,000 feet higher than the Manchurian peaks, but as you can see from the picture, it is only 10,000 feet above sea level.\\nWhat is the highest mountain in the world?\\nThe mountain's peak is 20,000 feet higher than the Manchurian peaks, but as you can see from the picture, it is only 10,000 feet above sea level.\"\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: \"\\nI've never written a function in Python before. I thought it was only for String and ByteSites.  Thanks for the help :)\\nPython is a very simple language, and there are a lot of tutorials out there on how to use it.\"\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: '\\nlife, love, and friends.\\n\\nSearch This Blog\\n\\nPages\\n\\nWednesday, July 23, 2010\\n\\nIs Your Inner Brother a Friend?\\n\\nPosted by: JoAnn\\n\\nShe has been very strong lately. I love my family, but there are some that are a bit unfair. I am a mother of two young children. I am also a husband who is a father of two. I am a woman who loves both my sons and my daughters dearly. I love our family. I love my children dearly. I love the people who are around me. I love my family. I love my family. I love my family. I love my family.\\n\\nMy children have been living with me for many years. I am not sure about the other family. I think they would all like to be together. I love my family. I love my children dearly. I love my children dearly. I love my family. I love my family.\\n\\nThe house is a living room. I am so happy. It is a beautiful place to be. My son is 16. He is a 10 year old boy. He is fascinated with the sky and my sun. He also likes to hang out with me. I love my son'\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: \"\\nHaha, I thought I was the only one.\\nI don't think he is.\\nThat would be the weirdest story I have ever read.\\nI will take it.\\nI don't know if he will really have a chance to make it.\\nDo you have any suggestions?\\nWell, they are all out there.\\nI just have to figure out who to post them to first.\\nI will post them first.\\nI have found some really interesting ones on the web.\\nI have found a story that is about a cat.\\nIt is about a cat who is dead.\\nThe cat is trapped in a closet in a town.\\nThe town is a cat town.\\nIt has no animals.\\nThe cat's house is a cat town.\\nThe cat has been in the closet for a long time.\\nThe cat has an open closet that is to be used as a bedroom.\\nThe cat is set to sleep in the open closet until it dies.\\nIt is set to sleep in the open closet until it dies.\\nThe cat is set to die, but the cat has been sitting in the closet for long enough that it has died.\\nIt is set to die.\\nIt is set\"\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: '\\n>hello  Yes, hello.  It is better to be *parliamentary* in your native language, as opposed to \"foreign\".\\n>it is better to be *parliamentary* in your native language, as opposed to \"foreign\".  Yes.  This is the correct way.\\nDon\\'t worry, the translation is correct. \"hello\" is the translation of the word \"hello\" into Spanish.\\nI guess you can say the same thing about me or anyone who uses English, and yet I\\'m just as bad about that.\\nNo, you can say the same thing about me or anyone who uses English.\\nSurely the correct way is to say the same thing about me or anyone who uses English.'\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: '\\nPossibly Tokyo.'\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: \"\\nI don't know about that. It's a theory that involves some kind of physics that might be just as complicated as Newton's Theory.\\nAll I know is that one way to explain physics is a strong gravitational tug.  *I'm not saying that this theory is perfect, but it is possible, and it's possible, that the theory of relativity is the best explanation of physics.  *I'm not saying that this theory is perfect, but it is possible, and it's possible, that the theory of relativity is the best explanation of physics.\"\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: '\\nIs that a normal thing to do?\\nA poem is a lot of people\\'s work, and usually, a poem is written in a style you like, for obvious reasons.\\nSure, but it is an easy way to get yourself organized.\\nThis is all because you can keep the word \"poem\" as a title in a book.\\nAnd if you want to keep it as a title, you can keep it as a reminder of something that you\\'ve done.\\nTo make it more palatable, I added \"word\" and \"line\" to the title of the poem.\\nI also added \"hope\" and \"dream\" to the title of the poem.\\nSo, since you don\\'t want to do it \"in a book\" but as a title, why not?\\nI am glad you\\'re here.\\nHere are some examples of what I\\'ve gotten up to, and how I have grown and what I\\'ve learned.\\nWhat do you think?\\nHave you ever had a person who wasn\\'t happy, but didn\\'t want you to know?\\n(I want to know if this person was happy because he wanted you to know but didn\\'t want you to know.\\nHe could\\'ve made a deal with'\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: \"\\nIf you mean the highest mountain in the world, then yes.\\nDamn. That's the highest mountain in the world.\"\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: ' Once it is calculated, log the number so that it can be used to write a P-type matrix to calculate the factorial of the number. Then use the log to calculate the factorial of the number. Then, return the factorial of the number, and use the log to calculate the factorial of the number. Then, return the factorial of the number, and use the log to calculate the factorial of the number.'\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: \"\\nI'm asexual and everything I do I don't care.\\nI'm asexual too. I prefer to have sex in public.\"\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: \"   Or, write about an ancient artefact.  Or, you could include the cat in the story, but not necessarily the story.\\nI meant, I like to think I'm on my own with this, I'm just searching for my own story.\\nYou should try to make this your own thing instead of your own story.  For your story, try to not do it all yourself.\"\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: '  Spanish is one of the hardest languages to translate. I think I\\'m not doing it right. I\\'m a little confusing.\\nI use my Spanish to translate the words \"hello\" to Spanish. In my opinion that\\'s the best way to learn Spanish.  It\\'s quite simple, in fact it\\'s quite easy.  I\\'m not sure if it\\'s just me or this is just me being too lazy, but I\\'ve heard that it\\'s very difficult to get the right one.\\nI don\\'t know, I\\'ve never experienced that. I\\'m Spanish-American and have used the same method of translation, no problem. I don\\'t think it\\'s a matter of laziness or anything though. My Spanish teacher doesn\\'t really do anything for us, so I can\\'t really make any assumptions.'\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: \"\\nJapanese cities\\nI'm going to have to ask some friends to come to Tokyo first. It's nice to have in Japan, but I don't think I'll be able to make it.\\nI'm about to make an awesome friend in Tokyo, but I won't be able to make it, you're in the wrong place!\"\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: \"\\nHaha, I don't think I've read it before, but I just went to the comments, and I read it.\\nWell it is your theory. So if you read the books, then you can't use that theory to explain it. You must be someone else. You are just an idiot.\"\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: '\\nI love this idea, thank you!'\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: '\\nThe mountains in North America, the United States of America, are on the Great Divide.\\nIt is a very well established fact that mountain ranges include many mountain ranges.\\nHere is a list of the greatest mountain ranges in the world.\\n1.\\nThe Arctic is the biggest in the world.\\nIn fact, it is the largest in the world!\\n2.\\nThe Ice Age is more than 1.5 billion years old.\\nIn fact, it is the largest time period of the life of Earth.\\n3.\\nThe Arctic is the most ice-free period of any globe on earth.\\nIt is the third-fastest growing globe on earth.\\n4.\\nThe Arctic is the fifth-fastest growing globe on Earth.\\nIt is the seventh-fastest growing globe on earth.\\n5.\\nThe Arctic is the eighth-fastest growing globe on earth.\\nIt is the ninth-fastest growing globe on earth.\\n6.\\nThe Arctic is the tenth-fastest growing globe on earth.\\nIt is the fifteenth-fastest growing globe on earth.\\n7.\\nThe Arctic is the tenth-fastest growing globe on earth.\\nIt is the fifteenth-fastest'\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: ' The function uses logic to build the number and if the number is small, it will be written. Then, in the calculations, the number is used to calculate the number. This is how it works in Python.\\n\\nimport python from \"https://github.com/htb/signature\"\\n\\nThe first argument we make is the div div. This is an argument from the Python function.\\n\\nimport python from \"https://github.com/htb/signature\"\\n\\nIf a number is smaller than a div div, then the div div will be written to the div div. If a number is larger than a div div, then the div div will be written to the div div. If a number is smaller than a div div, then the div div will be written to the div div. If a number is smaller than a div div, then the div div will be written to the div div. If a number is greater than a div div, then the div div will be written to the div div.\\n\\nimport python from \"https://github.com/htb/signature\"\\n\\nThat way, we write the code for the div div. We need to add the value of the div div to the'\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: '\\n\\nThere are two kinds of people: people who think their lives are the way of others and people who think they are a stranger to society.\\n\\nYou are what you think you are, and you are what you think you are not.\\n\\nWhen I say you are what you think you are, I mean you are who you are, and that is what you are.\\n\\nIf you think you are you are. If you think you are not, then you are not who you are.\\n\\nYou are what you think you are, and you are what you are.\\n\\nDo you love who you are? Do you love who you are?\\n\\nDo you love your parents? Do you love your sisters? Do you love your brothers?\\n\\nDo you love your grandparents? Do you love your cousins? Do you love your parents?\\n\\nDo you love your sister? Do you love your mother? Do you love your aunt? Do you love your cousins? Do you love your brother?\\n\\nDo you love your father? Do you love your mother? Do you love your father? Do you love your aunt? Do you love your grandmother?\\n\\nDo you love your father? Do you love your mother? Do you'\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: \" And tell it to a friend.\\nShe likes it! I'll check it out\\nIt is a really nice read. I love how your cat has become familiar with the story. :)\\nHaha I've told her to try and read it but she's always out of order and thinks I'm the bad one. So she thinks I'm the good one and then turns on me when she gets sad\"\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: ' You\\'re very welcome!\\nSo, I can read it in Spanish and then I can say \"Hello\" to the whole world?'\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: \" I'm in the U.S.\\nIs the capital of Japan what Japan is?\\nIt's an even more famous example of the plot of the series.\\nInteresting. I was curious about the name since I don't remember it, but it sounds like it could be Tokyo.\"\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: '\\nJust like how we could understand how relativity works.   When we understand that relativity is an illusion, we can do so *in* the system.\\nI never understood why an illusionary theory was called a \"properly explained theory\".   I guess it was just a case of getting used to the idea, and then I got bored of the idea.\\nIt\\'s a vague theory that the universe is constantly changing and it\\'s very hard to follow. The universe doesn\\'t just change in the way we think about it, but the way we think about it.\\nThe universe is constantly changing, it\\'s only a matter of time before it reaches a point where it does. It\\'s not complicated.\\nNot really. The universe doesn\\'t always change, it\\'s just unpredictable.'\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: \"\\nI've thought about it but I never feel like this until I get to the beach or something. I have to stop thinking about it.\\nMe too. I will try to think about it when I get home, but don't have the energy to do that right now.\"\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: '\\n\\nThe Rocky Mountain National Park is one of the most beautiful and exotic mountain ranges in the world. The mountain ranges are gorgeous and it is also a place where you can find the wildlife of the world.\\n\\nThe Rocky Mountain National Park is a lot of fun and the opportunities are endless. You can hike, hike, snorkel, ski, and ski, and there is no limit to what you can do at the park.\\n\\nThere are many activities that you can do at the park, and if you want to take a break, you can do some hiking and bike rides.\\n\\nThe Rocky Mountain National Park is famous for its variety of wildlife, and it is also a place where you can look around the world. There are many wildlife lovers, and there is no reason to not enjoy all that there is to see and see.\\n\\nThe Rocky Mountain National Park is one of the most beautiful places in the world. It is a great place to walk, ride horseback, and have a good time. It is home to hundreds of animals that are very special and welcome visitors.\\n\\nThe Rocky Mountain National Park is an amazing place to go for a good adventure. You can also visit the waterfalls, the sunsets, the trees'\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: \"\\nWhat's your definition for that?\"\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: '\\nI believe you are being serious, but I want you to know that there are lots of different kinds of things that we can do to survive.\\nI think it\\'s more like \"I\\'m not sure what I want to be.\"  You can be anything you want, but I don\\'t know where it is or who is willing to commit to that.  I think it\\'s going to be impossible for me to know.\\n> I think it\\'s more like \"I\\'m not sure what I want to be.\"  You just said it, man.  It\\'s like \"I\\'m not sure what I want to be.\"  I was just trying to make an observation.  My current life isn\\'t what it used to be.  It\\'s just the opposite.  I\\'ve become more and more dissatisfied with myself.\\nThank you for the well taken and well observed observation.  I will continue to do my best to make myself not feel this way.'\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: \" If you have cat, tell him you don't want him dead.\\nIt sounds like OP is a cat person.   > What if he is a cat person, OP?\"\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: '\\nI’m working on it in Spanish. I think I’ll put it into the same language as the English version and figure out what it means.'\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: \"\\nJapan is the capital of the USA.\\nActually, the capital of the US is Berlin.\\nAh. You're right.\"\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: \" I'd like to know if it's true.\\nThe universe is constricted by the laws of gravity. The universe is no different than any other universe.\"\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: \"\\nI thought about that already, but I'm not sure if I want to start, since it's a small project, but I'll try.\\nI think I'm going to try a bit more than that.\"\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: '\\nMissouri.'\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: '\\nThat\\'s why I said \"if\" instead of \"if not\".  It\\'s just a word on the page (ie \"if not\" is what you should be thinking)\\nThanks for the clarification. Now I just googled it.'\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: '\\n\\nAnytime you plan to explore the world or to take a break from work, you’re going to want to know what the meaning of life is. The reason is you’re going to want to have a more fulfilling life, and you’re going to want to be a better person.\\n\\nSo it’s a good idea to know what the meaning of life is. That is, what life is about. It’s about serving others with love, caring, and compassion.\\n\\nThere are many things that life is about. There are other things you can do to create an enjoyable and fulfilling life. You can do anything in life you want.\\n\\nWatch out for these.\\n\\nConsider yourself lucky if you have the desire and the courage to explore the world. You will be lucky if you are able to enjoy your life.'\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: '\\n\\nUse a quote that would make the reader feel like they were in a cat’s head.\\n\\nUse the phrase “nothing” in your paragraph.\\n\\nWhen you write a story, keep it short. It is important to avoid too long words. Don’t use too many words in your story. You’ll find yourself asking yourself, “Why am I doing this?”\\n\\nI like to use words like “energy.” When I write a short story about a cat, it’s important to use the word “energy.” When I write a story about a dog, it’s important to use the word “energy.” When I write a story about a cat, it’s important to use the word “energy.” When I write a story about a dog, it’s important to use the word “energy.” When I write a story about a cat, it’s important to use the word “energy.”\\n\\nDo not overdo it.\\n\\nWhen you write a short story about a cat, it’s important to overdo it.\\n\\nDon'\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: '\\nI always seem to take that as \"hello,\" lol. I just started using it a couple of weeks ago.'\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: \"\\nTokyo.\\nWhy are you in Japan?\\nBecause I'm a rich Japanese guy and my family is poor.  I'm a university student who doesn't have to live with my parents in the Japanese Embassy.\"\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: '\\nIt’s relativity. It’s what we call it. It’s so different from the Standard Operating Procedure that it changes everything about how the Universe is organized.'\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: '\\n\\nTuesday, December 15, 2007\\n\\nI met a man named Andy at a book store at 9:30 a.m. last week, and we ate lunch. I liked the color of his hair, and he looked really good in his new shirt. The other day I saw him walking around the block in his old shirt. I just thought, \"Why not?\" He\\'s my guy, and I\\'m just not going to sell a shirt to him on the internet.\\n\\nHe\\'s also in my family. He\\'s a friend of mine. I\\'m not sure if we\\'ve ever met before.\\n\\nIt\\'s not like I\\'m going to tell him that I\\'ve been a fan of his. It\\'s like he\\'s the only person I\\'ve ever known who has ever had sex with me. It\\'s a guy that I\\'d never asked out before, and he\\'s a guy I\\'ve always liked.\\n\\nIt\\'s just not like I\\'m going to tell him that I\\'ve been a fan of his. It\\'s like he\\'s the only person I\\'ve ever known who has ever had sex with me. It\\'s a guy that I\\'d never asked out before, and he\\'s a guy I\\'ve always liked. It\\'s a guy'\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: '\\n\\nWhat is the greatest common factor of 110 and 1260?\\n60\\nCalculate the greatest common divisor of 6516 and 38.\\n38\\nCalculate the highest common factor of 4 and 368.\\n2\\nWhat is the highest common factor of 15 and 20870?\\n5\\nCalculate the highest common factor of 16 and 3976.\\n16\\nCalculate the highest common divisor of 4 and 467.\\n1\\nCalculate the highest common divisor of 13 and 1089.\\n13\\nCalculate the greatest common factor of 14 and 16.\\n2\\nCalculate the greatest common divisor of 651 and 7.\\n7\\nWhat is the highest common factor of 20 and 584?\\n2\\nWhat is the highest common factor of 12 and 828?\\n12\\nCalculate the greatest common divisor of 168 and 1456.\\n21\\nWhat is the highest common factor of 674 and 9?\\n9\\nWhat is the greatest common divisor of 24 and 16?\\n4\\nWhat is the greatest common divisor of 128 and 6?\\n4\\nWhat is the highest common divisor of 664'\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: '\\n\\nOur function is a nice way to tell what is true in the calculation. We can do this by using a simple two-part function:\\n\\nTest our function\\n\\nWe can use our function to start with the number, but it will continue to take us until we reach a certain number in which case we must return a constant value.\\n\\nBy default, the Python function that we first start with is called here. You can also use our function to map the number to the subbarcode that you want to get in the calculation.\\n\\nNext, we can use our function to calculate the factorial of a number:\\n\\n$ test $ test $ test\\n\\nWe can also use our function to map the factorial to the subbarcode we want to get in the calculation.\\n\\nThis function is called here because we need to give the number a set of values in the a square root of the number we think the thing is in the calculation.\\n\\nThis is a nice way to tell what is true in the calculation. We can do this by using a simple two-part function:\\n\\nTest our function\\n\\nWe can use our function to start with the number, but it will continue to take us until we reach'\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: \" It's like a fantasy novel.\\nThe only human life is always a human being.\\nIt's as if we are but not the whole thing.\\nThe real human being is always a human being.\"\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: \" Post a short story about a cat.\\nI know what you mean. I'm still trying to think of a name for my cat.\"\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: \"\\nOh, sorry, I didn't know how to do that. Thank you for your time!\"\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: '\\nJapan is the capital of the US.\\nSo the capital of Germany?\\nYes.'\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: \"\\nIt doesn't need to be explained, they just need to say what happens in the universe.\"\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: '\\nThis actually sounds like a good idea.'\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: '\\nHaltano in the Alps.'\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: \"\\n\\nThis function checks if the number has the upper limit. If it doesn't, check if the number has a lower limit.\\n\\n$ python class parameter {\\n\\n__return __new__(0, ==c) {\\n\\n}\\n\\n}\\n\\nNote that the null part of this function returns when the parameter has a lower limit and when the parameter has an upper limit.\\n\\nTip: If the parameter has an upper limit, it will now be considered null if it has an upper limit.\\n\\nWriting function in Python\\n\\nYou can write a function that treats the number of the second element in the range $x (without the element argument) as $y (without the element argument).\\n\\nYou can find out how to do this in the Python function.\\n\\nUsing a function that treats the number of the second element in the range $x (without the element argument) as $y (without the element argument) is a good idea to keep in mind when writing a function that is not defined in the Python function.\\n\\nExample:\\n\\n$ python $my = $my;\\n\\nThe function is written in Python. It treats the number of the second element in the range $x (without the element\"\n",
            "Generated\n",
            "Prompt: 'What is the meaning of life?', Generated text: '\\nThe meaning of life is how we live.'\n",
            "Generated\n",
            "Prompt: 'Write a short story about a cat.', Generated text: '\\nCan you give me a link to that story?\\nJust a story about a cat, not a story about a cat.'\n",
            "Generated\n",
            "Prompt: \"Translate 'hello' to Spanish.\", Generated text: \"\\nThat's the trick. You'll have to use the ae if you do it in your native language, though.\\nUnless you're a Spanish speaker.\"\n",
            "Generated\n",
            "Prompt: 'What is the capital of Japan?', Generated text: '  Edit: I just found out, Japan is capital of Japan.\\nMogashin, I think.\\nThank you, it is.'\n",
            "Generated\n",
            "Prompt: 'Explain the theory of relativity.', Generated text: \" I don't understand the concept of relativity.\\nWell there is a theory that states if you have a laser pointer, you can see the light coming from your eye. If you don't have it, you can see a very light sphere through it and have a very small amount of light. It's called the gravitationally charged electron and it is so powerful that you can see the light coming from your eye.\\nI feel like that's what relativity does, but relativity doesn't exist.  It has no meaning unless you see the light coming from your eye, which is a very powerful thing.\"\n",
            "Generated\n",
            "Prompt: 'Write a poem about the ocean.', Generated text: \"\\nNever thought I'd see this.  I've considered doing a poem about the ocean but I'd like to keep it short and concise so it gets posted on reddit and not the news.\"\n",
            "Generated\n",
            "Prompt: 'What is the highest mountain in the world?', Generated text: \"\\nI'm pretty sure it's Sierra Nevada.\\nIt's Mt. San Bruno!\"\n",
            "Generated\n",
            "Prompt: 'Write a Python function to calculate the factorial of a number.', Generated text: '\\nThis is a bit much, because if you program a function to get the factorial of a number, then it will never be a function.'\n",
            "Generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔢📊 Generating Embeddings with vLLM**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H_2bH95Qoqq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Hello, my name is\",\n",
        "    \"The president of the United States is\",\n",
        "    \"The capital of France is\",\n",
        "    \"The future of AI is\",\n",
        "]\n",
        "\n",
        "model = LLM(\n",
        "    model=\"facebook/opt-125m\",\n",
        "    task=\"embed\",\n",
        "    enforce_eager=True,\n",
        ")\n",
        "\n",
        "outputs = model.embed(prompts)\n",
        "\n",
        "for prompt, output in zip(prompts, outputs):\n",
        "    embeds = output.outputs.embedding\n",
        "    embeds_trimmed = ((str(embeds[:16])[:-1] +\n",
        "                       \", ...]\") if len(embeds) > 16 else embeds)\n",
        "    print(f\"Prompt: {prompt!r} | \"\n",
        "          f\"Embeddings: {embeds_trimmed} (size={len(embeds)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "ee8b7ec41b5f47e0b122c6f208225c5d",
            "616050f2ed7843a3ad748f076748aae7",
            "75d04b58aabc4942acb57f419e3745f2",
            "3ab91e0b261d40e6ad388176243e4254",
            "ed0fc5959a9e44aca6f156a2e232c627",
            "89d4b7c13ede4d8ab50dc7e05d278d5b",
            "7135dd96d0004aff8317d29aa60dd978",
            "0131252772fa4a1fa03b48ea51ac1270",
            "f6365d100c204588b26fe036e35ba16b",
            "a2e8a033fa4b41b096b95bb0252c24f2",
            "85a28d63ee724726a8899d7100d6d1a4"
          ]
        },
        "id": "ixP6zikpmu9j",
        "outputId": "3dec7d00-3566-438e-da62-172075f9a940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 02-13 18:43:32 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 02-13 18:43:32 config.py:678] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 02-13 18:43:32 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='facebook/opt-125m', speculative_config=None, tokenizer='facebook/opt-125m', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=facebook/opt-125m, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=PoolerConfig(pooling_type=None, normalize=None, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
            "INFO 02-13 18:43:33 model_runner.py:1110] Starting to load model facebook/opt-125m...\n",
            "INFO 02-13 18:43:33 weight_utils.py:252] Using model weights format ['*.bin']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pt checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee8b7ec41b5f47e0b122c6f208225c5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-13 18:43:34 model_runner.py:1115] Loading model weights took 0.2404 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 4/4 [00:00<00:00, 172.53it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'Hello, my name is' | Embeddings: [-0.00507354736328125, -0.00450897216796875, 0.01849365234375, -0.0009889602661132812, -0.041412353515625, 0.0150146484375, -0.00574493408203125, -0.08074951171875, -0.01068878173828125, -0.07305908203125, -0.0005578994750976562, 0.0017375946044921875, 0.04986572265625, -0.0155792236328125, 0.02618408203125, 0.022125244140625, ...] (size=768)\n",
            "Prompt: 'The president of the United States is' | Embeddings: [-0.01168060302734375, 0.253173828125, 0.0169677734375, 0.052276611328125, 0.0198974609375, 0.0234222412109375, -0.028961181640625, -0.04693603515625, -0.040771484375, -0.004718780517578125, -0.0164031982421875, 0.0290069580078125, -0.0235137939453125, -0.0102386474609375, 0.012908935546875, -0.0138397216796875, ...] (size=768)\n",
            "Prompt: 'The capital of France is' | Embeddings: [-0.035308837890625, 0.29638671875, 0.023223876953125, -0.0157318115234375, 0.0103607177734375, 0.032806396484375, -0.003387451171875, -0.00922393798828125, -0.0819091796875, 0.0007719993591308594, 0.0026607513427734375, 0.0266265869140625, -0.0084075927734375, -0.00769805908203125, -0.03289794921875, 0.0202484130859375, ...] (size=768)\n",
            "Prompt: 'The future of AI is' | Embeddings: [-0.0377197265625, 0.2054443359375, 0.01311492919921875, 0.00577545166015625, 0.0048828125, 0.00018405914306640625, -0.003429412841796875, -0.0074462890625, -0.053955078125, 0.05059814453125, -0.0306243896484375, 0.0031871795654296875, 0.0280303955078125, 0.062103271484375, -0.029083251953125, 0.01361846923828125, ...] (size=768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🧐📊 Text Classification with vLLM**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "67NqBKodouBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Hello, my name is\",\n",
        "    \"The president of the United States is\",\n",
        "    \"The capital of France is\",\n",
        "    \"The future of AI is\",\n",
        "]\n",
        "\n",
        "model = LLM(\n",
        "    model=\"facebook/opt-125m\",\n",
        "    task=\"classify\",\n",
        "    enforce_eager=True,\n",
        ")\n",
        "\n",
        "outputs = model.classify(prompts)\n",
        "\n",
        "for prompt, output in zip(prompts, outputs):\n",
        "    probs = output.outputs.probs\n",
        "    probs_trimmed = ((str(probs[:16])[:-1] +\n",
        "                      \", ...]\") if len(probs) > 16 else probs)\n",
        "    print(f\"Prompt: {prompt!r} | \"\n",
        "          f\"Class Probabilities: {probs_trimmed} (size={len(probs)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "932e86e395bc4f228e3c9b79c7d44918",
            "776b318f584c4b5bafc2c75a91b95c39",
            "2f990482a3264256aab6eddd046320d3",
            "f5152298674343c9aa1d08745aaa261c",
            "f43ce55c856b493c965243a1d7e02ef2",
            "b336e66e62bc4238b085f8f384a609e7",
            "292b4bab51294ed29efdb2b9e4701223",
            "c2a0ddc7871b463487f3cc64d26e3ee2",
            "9b4aa9f22e824c5eb48b168ab6ca671f",
            "0ee83fe532a64f03a9c62a0d7d963a3a",
            "f698ff91a7e94588854d49161ca3c848"
          ]
        },
        "id": "KbyNQAdHnp9_",
        "outputId": "a825055f-b969-41e3-ffd5-5800b2ce9f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 02-13 18:44:12 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 02-13 18:44:12 config.py:678] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 02-13 18:44:12 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='facebook/opt-125m', speculative_config=None, tokenizer='facebook/opt-125m', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=facebook/opt-125m, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=PoolerConfig(pooling_type=None, normalize=None, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
            "INFO 02-13 18:44:13 model_runner.py:1110] Starting to load model facebook/opt-125m...\n",
            "INFO 02-13 18:44:13 weight_utils.py:252] Using model weights format ['*.bin']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pt checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "932e86e395bc4f228e3c9b79c7d44918"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-13 18:44:14 model_runner.py:1115] Loading model weights took 0.2398 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 4/4 [00:00<00:00, 147.78it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'Hello, my name is' | Class Probabilities: [1.0, 0.0] (size=2)\n",
            "Prompt: 'The president of the United States is' | Class Probabilities: [1.0, 1.1920928955078125e-07] (size=2)\n",
            "Prompt: 'The capital of France is' | Class Probabilities: [0.9990234375, 0.0010175704956054688] (size=2)\n",
            "Prompt: 'The future of AI is' | Class Probabilities: [1.0, 0.00011682510375976562] (size=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}