{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWYoROUn85P_"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
        "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18et5X8LNS-UtgS3e5RLQrgSIHzwU3v4w?usp=sharing)\n",
        "## Master Generative AI in 6 Weeks\n",
        "**What You'll Learn:**\n",
        "- Build with Latest LLMs\n",
        "- Create Custom AI Apps\n",
        "- Learn from Industry Experts\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "*Empowering the Next Generation of AI Innovators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRx3wbfD84-r"
      },
      "source": [
        "# üö© **FlagEmbedding Overview**  \n",
        "\n",
        "FlagEmbedding is an open-source project for improving **information retrieval** and **LLM augmentation** using advanced embeddings. üß†  \n",
        "\n",
        "## üåü **Key Features**  \n",
        "- **BGE M3-Embedding** üåç: Multi-lingual, multi-granular, supports dense & sparse retrieval.  \n",
        "- **Visualized-BGE** üñºÔ∏è: Combines text & image embeddings for hybrid retrieval.  \n",
        "- **LM-Cocktail** üçπ: Merges fine-tuned & base models for better adaptability.  \n",
        "- **LLM Embedder** ü§ñ: Optimized for **knowledge, memory & tool retrieval**.  \n",
        "- **BGE Reranker** üîÑ: Re-ranks top-k results for higher accuracy.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdvwcF6Z84co"
      },
      "source": [
        "### **FlagEmbedding Installation**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W01DITGU8auY"
      },
      "outputs": [],
      "source": [
        "pip install -U FlagEmbedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üöÄ **FlagEmbedding Model Initialization**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ts4kSM35SbmH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPUGxHeo87n-"
      },
      "outputs": [],
      "source": [
        "from FlagEmbedding import FlagAutoModel\n",
        "\n",
        "model = FlagAutoModel.from_finetuned('BAAI/bge-base-en-v1.5',\n",
        "                                      query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
        "                                                                            use_fp16=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† **Encoding Sentences with FlagEmbedding**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tr3QN3JBSgDi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gDowef39BsQ",
        "outputId": "d0f28b45-57d0-493a-b36e-baf2ec18a047"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "sentences_1 = [\"I love NLP\", \"I love machine learning\"]\n",
        "sentences_2 = [\"I love BGE\", \"I love text retrieval\"]\n",
        "embeddings_1 = model.encode(sentences_1)\n",
        "embeddings_2 = model.encode(sentences_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç **Computing Sentence Similarity**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z5nfFAchSkdr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MuNBbC19JmQ",
        "outputId": "0383bb8c-de61-44ca-9be1-6eb6d2b707fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.6538745  0.7568528 ]\n",
            " [0.6559792  0.72265273]]\n"
          ]
        }
      ],
      "source": [
        "similarity = embeddings_1 @ embeddings_2.T\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf0WRMspADKd"
      },
      "source": [
        "### üöÄ **AutoReranker**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYfEoePD-wIF",
        "outputId": "ab7c9771-c6c8-4373-a6a9-d1683b45594f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.513671875]\n",
            "[0.1803952588642227]\n",
            "[-5.60546875, 5.76171875]\n",
            "[0.0036642203307843528, 0.9968641641227171]\n"
          ]
        }
      ],
      "source": [
        "from FlagEmbedding import FlagAutoReranker\n",
        "\n",
        "reranker = FlagAutoReranker.from_finetuned('BAAI/bge-reranker-large',\n",
        "                                           query_max_length=256,\n",
        "                                           passage_max_length=512,\n",
        "                                           use_fp16=True,\n",
        "                                           devices=['cuda:0'])\n",
        "\n",
        "score = reranker.compute_score(['query', 'passage'])\n",
        "print(score)\n",
        "\n",
        "score = reranker.compute_score(['query', 'passage'], normalize=True)\n",
        "print(score)\n",
        "\n",
        "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
        "print(scores)\n",
        "\n",
        "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']], normalize=True)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîÑ **Normal Reranker**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-1Iv6aZZDgiw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-Z-dEh__3Mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e59d10-abcc-4c00-e645-0237a2c7e5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-5.66015625]\n",
            "[0.003469890732315233]\n",
            "[-8.1796875, 5.26171875]\n",
            "[0.00028021097671886315, 0.9948403768236574]\n"
          ]
        }
      ],
      "source": [
        "from FlagEmbedding import FlagReranker\n",
        "reranker = FlagReranker(\n",
        "    'BAAI/bge-reranker-v2-m3',\n",
        "    query_max_length=256,\n",
        "    passage_max_length=512,\n",
        "    use_fp16=True,\n",
        "    devices=['cuda:0']\n",
        ")\n",
        "\n",
        "score = reranker.compute_score(['query', 'passage'])\n",
        "print(score)\n",
        "\n",
        "score = reranker.compute_score(['query', 'passage'], normalize=True)\n",
        "print(score)\n",
        "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
        "print(scores)\n",
        "\n",
        "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']], normalize=True)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ñ **LLM Reranker**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MrwMX1QRDk9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from FlagEmbedding import LayerWiseFlagLLMReranker\n",
        "reranker = LayerWiseFlagLLMReranker(\n",
        "    'BAAI/bge-reranker-v2-minicpm-layerwise',\n",
        "    query_max_length=256,\n",
        "    passage_max_length=512,\n",
        "    use_fp16=True,\n",
        "    devices=['cuda:0']\n",
        ")\n",
        "\n",
        "score = reranker.compute_score(['query', 'passage'], cutoff_layers=[28])\n",
        "print(score)\n",
        "\n",
        "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']], cutoff_layers=[28])\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "hJ3nQnOlDbB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}