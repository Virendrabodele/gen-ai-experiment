{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ux_AYLctM3qleYbXyUKE-ZF0m9KOBuF1?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "- Join Innovation Community\n",
        "\n",
        "Learn by building. Get expert mentorship and work on real AI projects.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akEWCai0Sict"
      },
      "source": [
        "## Structured Outputs from OpenAI Client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7_Q2-UmZi7e"
      },
      "source": [
        "Notebook by [Build Fast with AI](https://www.buildfastwithai.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJds2F4YECoa",
        "outputId": "31b9f3c7-6c41-41bf-9891-6d21b37d986b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.4/360.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcVNncWSEE4S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dyOVhRs8pYI",
        "outputId": "b75c68a7-92cb-47ac-d24a-962e616c6072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Satvik\n",
            "18\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "\n",
        "class UserInfo(BaseModel):\n",
        "  name: str\n",
        "  age: int\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Satvik is 18 years old\"}],\n",
        "    response_format=UserInfo,\n",
        ")\n",
        "\n",
        "message = completion.choices[0].message\n",
        "print(message.parsed.name)\n",
        "print(message.parsed.age)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J9MvE9lETGG"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "class Step(BaseModel):\n",
        "    explanation: str\n",
        "    output: str\n",
        "\n",
        "\n",
        "class MathResponse(BaseModel):\n",
        "    steps: list[Step]\n",
        "    final_answer: str\n",
        "\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"solve 8x + 31 = 2\"},\n",
        "    ],\n",
        "    response_format=MathResponse,\n",
        ")\n",
        "\n",
        "message = completion.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "DPKyhK6IE1il",
        "outputId": "8d011ab7-61c9-47a3-88a9-2b086ff47ab5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"steps\":[{\"explanation\":\"First, subtract 31 from both sides of the equation to isolate the term with the variable on one side.\",\"output\":\"8x + 31 - 31 = 2 - 31\"},{\"explanation\":\"Simplify both sides. The left side becomes 8x and the right side becomes -29.\",\"output\":\"8x = -29\"},{\"explanation\":\"Next, divide both sides by 8 to solve for x.\",\"output\":\"x = \\\\\\\\frac{-29}{8}\"}],\"final_answer\":\"x = -\\\\\\\\frac{29}{8}\"}'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w06ueNIyFoSp",
        "outputId": "18749ca7-65c5-4e2b-86bd-cd0c3c31cdba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MathResponse(steps=[Step(explanation='Subtract 31 from both sides to isolate the term with x.', output='8x + 31 - 31 = 2 - 31')], final_answer='8x = -29')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1SJsjahQ5kd"
      },
      "outputs": [],
      "source": [
        "message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI_HFUTME3Fl",
        "outputId": "6fad70f1-a8f9-455d-f6fd-fdb504e10152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step(explanation='First, subtract 31 from both sides of the equation to isolate the term with the variable on one side.', output='8x + 31 - 31 = 2 - 31'), Step(explanation='Simplify both sides. The left side becomes 8x and the right side becomes -29.', output='8x = -29'), Step(explanation='Next, divide both sides by 8 to solve for x.', output='x = \\\\frac{-29}{8}')]\n",
            "x = -\\frac{29}{8}\n"
          ]
        }
      ],
      "source": [
        "if message.parsed:\n",
        "    print(message.parsed.steps)\n",
        "    print(message.parsed.final_answer)\n",
        "else:\n",
        "    print(message.refusal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0SFFNH2F55e",
        "outputId": "8e3ea31e-e5c0-4df7-b0c7-244b3a67c149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "table_name=<Table.orders: 'orders'> columns=[<Column.id: 'id'>, <Column.status: 'status'>, <Column.expected_delivery_date: 'expected_delivery_date'>, <Column.delivered_at: 'delivered_at'>, <Column.shipped_at: 'shipped_at'>, <Column.ordered_at: 'ordered_at'>, <Column.canceled_at: 'canceled_at'>] conditions=[Condition(column='shipped_at', operator=<Operator.ge: '>='>, value='2023-05-01'), Condition(column='shipped_at', operator=<Operator.le: '<='>, value='2023-05-31'), Condition(column='status', operator=<Operator.eq: '='>, value='fulfilled'), Condition(column='delivered_at', operator=<Operator.gt: '>'>, value=DynamicValue(column_name='expected_delivery_date'))] order_by=<OrderBy.asc: 'asc'>\n"
          ]
        }
      ],
      "source": [
        "from enum import Enum\n",
        "from typing import Union\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "class Table(str, Enum):\n",
        "    orders = \"orders\"\n",
        "    customers = \"customers\"\n",
        "    products = \"products\"\n",
        "\n",
        "\n",
        "class Column(str, Enum):\n",
        "    id = \"id\"\n",
        "    status = \"status\"\n",
        "    expected_delivery_date = \"expected_delivery_date\"\n",
        "    delivered_at = \"delivered_at\"\n",
        "    shipped_at = \"shipped_at\"\n",
        "    ordered_at = \"ordered_at\"\n",
        "    canceled_at = \"canceled_at\"\n",
        "\n",
        "\n",
        "class Operator(str, Enum):\n",
        "    eq = \"=\"\n",
        "    gt = \">\"\n",
        "    lt = \"<\"\n",
        "    le = \"<=\"\n",
        "    ge = \">=\"\n",
        "    ne = \"!=\"\n",
        "\n",
        "\n",
        "class OrderBy(str, Enum):\n",
        "    asc = \"asc\"\n",
        "    desc = \"desc\"\n",
        "\n",
        "\n",
        "class DynamicValue(BaseModel):\n",
        "    column_name: str\n",
        "\n",
        "\n",
        "class Condition(BaseModel):\n",
        "    column: str\n",
        "    operator: Operator\n",
        "    value: Union[str, int, DynamicValue]\n",
        "\n",
        "\n",
        "class Query(BaseModel):\n",
        "    table_name: Table\n",
        "    columns: list[Column]\n",
        "    conditions: list[Condition]\n",
        "    order_by: OrderBy\n",
        "\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful assistant. The current date is August 6, 2024. You help users query for the data they are looking for by calling the query function.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"look up all my orders in may of last year that were fulfilled but not delivered on time\",\n",
        "        },\n",
        "    ],\n",
        "    tools=[\n",
        "        openai.pydantic_function_tool(Query),\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.tool_calls[0].function.parsed_arguments)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
