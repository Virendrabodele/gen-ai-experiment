{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZKrP-_36l23"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1javgioAI6eSXQ3KNnhNvYbAhwIKmVJXB?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "\n",
        "Learn by building. Get expert mentorship and work on real AI projects.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKy3SpsM6jiJ"
      },
      "source": [
        "#Testing GPT-OSS Model via OpenRouter\n",
        "This notebook provides a comprehensive guide to using the GPT-OSS model through OpenRouter's API, integrated with the LangChain framework. It includes everything from setup to advanced use cases.\n",
        "\n",
        "⚠️ Note: You will need a free API key from OpenRouter to execute the examples below."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##About the GPT-OSS Model\n",
        "- OpenAI‑OSS models (like gpt-oss‑120B and gpt-oss‑20B) are fully open-weight under the Apache 2.0 license, enabling download, customization, and local execution\n",
        "\n",
        "\n",
        "- These models deliver strong logical reasoning performance—especially on STEM and chain-of-thought benchmarks—comparable to OpenAI's o4-mini models\n",
        "\n",
        "- OpenRouter acts as a unified gateway to these models (and 300+ others), offering routing, automatic fallbacks, and consistent OpenAI-compatible API access\n",
        "\n",
        "- Seamlessly integrates with LangChain, LlamaIndex, and other frameworks via the standard Chat Completions API for agentic and chat-based workflows\n"
      ],
      "metadata": {
        "id": "VB-FZj5A1mNn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfaRziHC6jiM"
      },
      "source": [
        "###Installation\n",
        "\n",
        "First, let's install the necessary Python libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TjlR0IIK6jiN",
        "outputId": "591e816e-0b6b-479b-d3a7-69f7092885cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.28)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.11-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.97.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Downloading langchain_tavily-0.2.11-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: langchain-tavily\n",
            "Successfully installed langchain-tavily-0.2.11\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai langchain_community langchain-tavily"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzofWxWtxHgU"
      },
      "source": [
        "###import API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPXW1N1ZxHCI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dTJ4-AV6jiO"
      },
      "source": [
        "###Basic Usage with ChatOpenAI and OpenRouter\n",
        "\n",
        "- Here’s how to set up the `ChatOpenAI` class to connect to the Qwen model through OpenRouter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5A3jXql6jiO",
        "outputId": "118fe605-700a-44c3-9c5a-cc2e8f0efcb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I was created by the research and engineering teams at **OpenAI**. I'm built on the GPT‑4 architecture, which is a large language model they developed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# It's recommended to set your API key as an environment variable\n",
        "api_key = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "# Initialize the ChatOpenAI model for Qwen\n",
        "gpt_oss = ChatOpenAI(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    openai_api_key=api_key,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "# Let's test it with a simple prompt\n",
        "response = gpt_oss.invoke(\"who developed you\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBYsDNig6jiP"
      },
      "source": [
        "### Multilingual Capabilities\n",
        "\n",
        "Qwen models are proficient in multiple languages. Let's test this by sending prompts in Hindi and Spanish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_tC8vos6jiP"
      },
      "outputs": [],
      "source": [
        "# Example in Hindi\n",
        "\n",
        "hindi_prompt = \"कृत्रिम बुद्धिमत्ता क्या है?\" # Translation: What is Artificial Intelligence?\n",
        "hindi_response = gpt_oss.invoke(hindi_prompt)\n",
        "\n",
        "print(f\"\"\"Response in Hindi:\n",
        "{hindi_response.content}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example in Spanish\n",
        "\n",
        "spanish_prompt = \"¿Cuál es la capital de Argentina?\" # Translation: What is the capital of Argentina?\n",
        "spanish_response = gpt_oss.invoke(spanish_prompt)\n",
        "\n",
        "print(f\"\"\"Response in Spanish:\n",
        "{spanish_response.content}\"\"\")"
      ],
      "metadata": {
        "id": "jvIfm5udxsvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAu9BXF46jiQ"
      },
      "source": [
        "### Advanced Parameter Tuning\n",
        "\n",
        "You can control the model's output by tuning parameters like `temperature` and `top_p`.\n",
        "\n",
        "- **`temperature`**: Controls randomness. Lower values (e.g., 0.1) make the output more deterministic, while higher values (e.g., 0.9) make it more creative.\n",
        "- **`top_p`**: Controls nucleus sampling. It considers only the tokens with the highest probability mass.\n",
        "- **`max_tokens`**: Sets the maximum length of the generated response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgpxAxGy6jiQ"
      },
      "outputs": [],
      "source": [
        "# Creative response with high temperature\n",
        "creative_llm = ChatOpenAI(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    openai_api_key=api_key,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    temperature=0.9,\n",
        ")\n",
        "\n",
        "prompt = \"Write a short, futuristic story about a cat who can code.\"\n",
        "creative_response = creative_llm.invoke(prompt)\n",
        "print(f\"\"\"Creative Story:\n",
        "{creative_response.content}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Factual response with low temperature\n",
        "factual_llm = ChatOpenAI(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    openai_api_key=api_key,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "prompt = \"Explain the theory of relativity in simple terms.\"\n",
        "factual_response = factual_llm.invoke(prompt)\n",
        "print(f\"\"\"\n",
        "Factual Explanation:\n",
        "{factual_response.content}\"\"\")"
      ],
      "metadata": {
        "id": "hjx3aLo1yWmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YILCRBuG6jiQ"
      },
      "source": [
        "### Building a Simple Chatbot\n",
        "\n",
        "We can create a simple conversational chatbot by managing the chat history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksog2Dsr6jiR"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "]\n",
        "\n",
        "print(\"Hello! I am ready to chat. Type 'quit' to end the conversation.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    messages.append(HumanMessage(content=user_input))\n",
        "\n",
        "    response = gpt_oss.invoke(messages)\n",
        "    print(f\"Assistant: {response.content}\")\n",
        "\n",
        "    # Add the bot's response to the history\n",
        "    messages.append(response)\n",
        "\n",
        "print(\"Goodbye!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Analysis and Visualization with Pandas & Matplotlib\n"
      ],
      "metadata": {
        "id": "w0Jo4TUx8uUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for data analysis and visualization\n",
        "prompt = \"\"\"\n",
        "Write a Python script that performs the following steps:\n",
        "1. Creates a sample Pandas DataFrame with columns 'Department', 'Employee', and 'Salary'. Include at least 10 rows of sample data.\n",
        "2. Calculates the average salary for each department using `groupby()`.\n",
        "3. Generates a bar chart of the average salaries per department using Matplotlib. The chart should have a title and labels for the x and y axes.\n",
        "\"\"\"\n",
        "\n",
        "# Let's test it\n",
        "response = gpt_oss.invoke(prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "FOYheSUd8twE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing Generated Code"
      ],
      "metadata": {
        "id": "ln-_Gdtf9CYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1️⃣  CREATE SAMPLE DATA\n",
        "# ----------------------------------------------------------------------\n",
        "data = {\n",
        "    \"Department\": [\n",
        "        \"Sales\", \"Sales\", \"Sales\", \"Marketing\", \"Marketing\",\n",
        "        \"HR\", \"HR\", \"Engineering\", \"Engineering\", \"Engineering\"\n",
        "    ],\n",
        "    \"Employee\": [\n",
        "        \"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\",\n",
        "        \"Frank\", \"Grace\", \"Henry\", \"Ivy\", \"Jack\"\n",
        "    ],\n",
        "    \"Salary\": [\n",
        "        68000, 72000, 71000,   # Sales\n",
        "        62000, 64000,          # Marketing\n",
        "        58000, 59000,          # HR\n",
        "        95000, 97000, 99000    # Engineering\n",
        "    ],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"=== Sample DataFrame ===\")\n",
        "print(df)\n",
        "print(\"\\n\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2️⃣  AVERAGE SALARY PER DEPARTMENT\n",
        "# ----------------------------------------------------------------------\n",
        "avg_salary = df.groupby(\"Department\")[\"Salary\"].mean().reset_index()\n",
        "print(\"=== Average Salary per Department ===\")\n",
        "print(avg_salary)\n",
        "print(\"\\n\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 3️⃣  BAR CHART WITH MATPLOTLIB\n",
        "# ----------------------------------------------------------------------\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Bar positions & heights\n",
        "bars = plt.bar(\n",
        "    avg_salary[\"Department\"],\n",
        "    avg_salary[\"Salary\"],\n",
        "    color=[\"steelblue\", \"seagreen\", \"tomato\"],   # optional: one colour per bar\n",
        "    edgecolor=\"black\"\n",
        ")\n",
        "\n",
        "# Annotate each bar with its exact value\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.annotate(\n",
        "        f\"${height:,.0f}\",\n",
        "        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "        xytext=(0, 5),               # 5 points vertical offset\n",
        "        textcoords=\"offset points\",\n",
        "        ha=\"center\",\n",
        "        va=\"bottom\",\n",
        "        fontsize=9,\n",
        "        color=\"black\",\n",
        "    )\n",
        "\n",
        "# Titles & labels\n",
        "plt.title(\"Average Salary by Department\", fontsize=14, pad=15)\n",
        "plt.xlabel(\"Department\", fontsize=12)\n",
        "plt.ylabel(\"Average Salary (USD)\", fontsize=12)\n",
        "\n",
        "# Optional: improve layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot (or replace with plt.savefig('avg_salary.png') to save)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-OcycZOt9CK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC59dEUCHWoh"
      },
      "source": [
        "###Tool Calling and Tavily Search Using GPT-OSS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfug1PTgHU1b"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "# 1. Setup LLM via OpenRouter\n",
        "llm = ChatOpenAI(\n",
        "    model=\"openai/gpt-oss-120b\", # Check OpenRouter.ai for valid IDs\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    openai_api_key=userdata.get(\"OPENROUTER_API_KEY\")\n",
        ")\n",
        "\n",
        "# 2. Setup Tavily Search Tool\n",
        "tavily_tool = TavilySearch(max_results=2)\n",
        "\n",
        "# 3. Create Agent\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant.\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "agent = create_tool_calling_agent(llm, [tavily_tool], prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=[tavily_tool], verbose=True)\n",
        "\n",
        "# 4. Run Agent\n",
        "response = agent_executor.invoke({\"input\": \"How do central bank interest rate changes affect the stock market?\"})\n",
        "print(response['output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3D Earth Visualization with Plotly"
      ],
      "metadata": {
        "id": "QVLn5bgU3ugU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup LLM via OpenRouter\n",
        "openai_oss = ChatOpenAI(\n",
        "    model=\"openai/gpt-oss-120b\", # Check OpenRouter.ai for valid IDs\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    openai_api_key=userdata.get(\"OPENROUTER_API_KEY\")\n",
        ")\n",
        "\n",
        "# Prompt for generating a 3D Earth visualization\n",
        "prompt = \"\"\"\n",
        "Write a Python script using the `plotly.graph_objects` and `pandas` libraries to create an interactive 3D visualization of the Earth.\n",
        "\n",
        "The script should perform the following steps:\n",
        "1.  Create a 3D sphere that visually represents the Earth. A blue sphere with a specific texture or color scale is ideal.\n",
        "2.  Define the latitude and longitude for a few major cities: London, New York, Tokyo, and Sydney.\n",
        "3.  Convert these latitude and longitude coordinates into 3D Cartesian (x, y, z) coordinates to be plotted on the sphere's surface.\n",
        "4.  Plot the cities as distinct markers on the 3D globe.\n",
        "5.  The final output should be an interactive 3D plot that can be rotated and zoomed.\n",
        "\"\"\"\n",
        "\n",
        "# Let's get the model to generate the script\n",
        "response = openai_oss.invoke(prompt)\n",
        "\n",
        "# The generated code will be printed below.\n",
        "print(\"--- Generated 3D Earth Visualization Code ---\")\n",
        "print(response.content)\n",
        "print(\"\\n--- End of Generated Code ---\")\n",
        "print(\"\\nIMPORTANT: Copy the code generated above into a new Colab cell and run it to see the interactive visualization.\")"
      ],
      "metadata": {
        "id": "tHR2kC5e3vP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing Code"
      ],
      "metadata": {
        "id": "d82833Kf6rSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You might need to install plotly first\n",
        "!pip install plotly pandas -q"
      ],
      "metadata": {
        "id": "XdihPad14iL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1.  Create the sphere (Earth)\n",
        "# ----------------------------------------------------------------------\n",
        "def create_earth_sphere(radius=1, n_theta=180, n_phi=360):\n",
        "    \"\"\"\n",
        "    Returns the (x, y, z) coordinates of a spherical surface.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    radius : float\n",
        "        Radius of the sphere.\n",
        "    n_theta : int\n",
        "        Number of points along the polar angle (0 → π). Controls vertical resolution.\n",
        "    n_phi : int\n",
        "        Number of points along the azimuthal angle (0 → 2π). Controls horizontal resolution.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple of np.ndarray\n",
        "        (X, Y, Z) arrays shaped (n_theta, n_phi).\n",
        "    \"\"\"\n",
        "    theta = np.linspace(0, np.pi, n_theta)          # polar angle\n",
        "    phi   = np.linspace(0, 2 * np.pi, n_phi)        # azimuthal angle\n",
        "\n",
        "    theta, phi = np.meshgrid(theta, phi)            # create grid\n",
        "\n",
        "    X = radius * np.sin(theta) * np.cos(phi)\n",
        "    Y = radius * np.sin(theta) * np.sin(phi)\n",
        "    Z = radius * np.cos(theta)\n",
        "\n",
        "    return X, Y, Z\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2.  Define city data (latitude, longitude) in a pandas DataFrame\n",
        "# ----------------------------------------------------------------------\n",
        "city_data = pd.DataFrame({\n",
        "    \"city\":    [\"London\", \"New York\", \"Tokyo\", \"Sydney\"],\n",
        "    \"lat_deg\": [51.5074, 40.7128, 35.6895, -33.8688],\n",
        "    \"lon_deg\": [-0.1278, -74.0060, 139.6917, 151.2093],\n",
        "    \"marker_color\": [\"red\", \"orange\", \"green\", \"purple\"],\n",
        "    \"marker_size\":  [8, 8, 8, 8]\n",
        "})\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 3.  Convert lat / lon to Cartesian coordinates on the sphere surface\n",
        "# ----------------------------------------------------------------------\n",
        "def latlon_to_cartesian(lat, lon, radius=1):\n",
        "    \"\"\"\n",
        "    Convert latitude and longitude (in degrees) to 3‑D Cartesian coordinates.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lat : float or array‑like\n",
        "        Latitude in degrees (positive = north).\n",
        "    lon : float or array‑like\n",
        "        Longitude in degrees (positive = east).\n",
        "    radius : float\n",
        "        Radius of the sphere.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple of np.ndarray\n",
        "        (x, y, z) coordinates.\n",
        "    \"\"\"\n",
        "    lat_rad = np.radians(lat)\n",
        "    lon_rad = np.radians(lon)\n",
        "\n",
        "    x = radius * np.cos(lat_rad) * np.cos(lon_rad)\n",
        "    y = radius * np.cos(lat_rad) * np.sin(lon_rad)\n",
        "    z = radius * np.sin(lat_rad)\n",
        "\n",
        "    return x, y, z\n",
        "\n",
        "city_x, city_y, city_z = latlon_to_cartesian(\n",
        "    city_data[\"lat_deg\"], city_data[\"lon_deg\"], radius=1\n",
        ")\n",
        "\n",
        "city_data[\"x\"] = city_x\n",
        "city_data[\"y\"] = city_y\n",
        "city_data[\"z\"] = city_z\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 4.  Build the Plotly figure\n",
        "# ----------------------------------------------------------------------\n",
        "# 4a – The Earth surface\n",
        "X_sphere, Y_sphere, Z_sphere = create_earth_sphere(radius=1)\n",
        "\n",
        "earth_surface = go.Surface(\n",
        "    x=X_sphere,\n",
        "    y=Y_sphere,\n",
        "    z=Z_sphere,\n",
        "    colorscale=[[0, \"rgb(0,30,100)\"], [1, \"rgb(0,120,250)\"]],  # simple blue gradient\n",
        "    showscale=False,\n",
        "    lighting=dict(\n",
        "        ambient=0.6,\n",
        "        diffuse=0.8,\n",
        "        fresnel=0.2,\n",
        "        specular=0.5,\n",
        "        roughness=0.9,\n",
        "    ),\n",
        "    hoverinfo=\"skip\",  # turn off hover for the surface itself\n",
        ")\n",
        "\n",
        "# 4b – City markers\n",
        "city_markers = go.Scatter3d(\n",
        "    x=city_data[\"x\"],\n",
        "    y=city_data[\"y\"],\n",
        "    z=city_data[\"z\"],\n",
        "    mode=\"markers+text\",\n",
        "    marker=dict(\n",
        "        size=city_data[\"marker_size\"],\n",
        "        color=city_data[\"marker_color\"],\n",
        "        opacity=0.9,\n",
        "        line=dict(width=1, color=\"black\"),\n",
        "    ),\n",
        "    text=city_data[\"city\"],      # label appears next to the marker\n",
        "    textposition=\"top center\",\n",
        "    hovertemplate=(\n",
        "        \"<b>%{text}</b><br>\"\n",
        "        \"Lat: %{customdata[0]:.2f}°<br>\"\n",
        "        \"Lon: %{customdata[1]:.2f}°<extra></extra>\"\n",
        "    ),\n",
        "    customdata=np.stack([city_data[\"lat_deg\"], city_data[\"lon_deg\"]], axis=-1),\n",
        ")\n",
        "\n",
        "# 4c – Combine into a figure\n",
        "fig = go.Figure(data=[earth_surface, city_markers])\n",
        "\n",
        "# Layout tweaks for a nice 3‑D view\n",
        "fig.update_layout(\n",
        "    title_text=\"Interactive 3‑D Earth with Major Cities\",\n",
        "    title_x=0.5,\n",
        "    scene=dict(\n",
        "        xaxis=dict(showbackground=False, visible=False),\n",
        "        yaxis=dict(showbackground=False, visible=False),\n",
        "        zaxis=dict(showbackground=False, visible=False),\n",
        "        aspectmode=\"data\",\n",
        "        camera=dict(\n",
        "            eye=dict(x=1.5, y=1.5, z=1.0)   # initial view angle\n",
        "        ),\n",
        "    ),\n",
        "    margin=dict(l=0, r=0, b=0, t=40),\n",
        "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "5yCk465w4Sda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t05mJ526jiS"
      },
      "source": [
        "###  Few-Shot Prompting\n",
        "\n",
        "Few-shot prompting provides the model with examples to guide its response format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDUW2gov6jiS"
      },
      "outputs": [],
      "source": [
        "prompt = (\n",
        "    \"\"\"Translate the following English words to French:\n",
        "\n",
        "    \"sea -> mer\"\n",
        "    \"sky -> ciel\"\n",
        "    \"book -> livre\"\n",
        "    \"house ->\"\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "few_shot_response = gpt_oss.invoke(prompt)\n",
        "print(f\"Translation of 'house': {few_shot_response.content}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}